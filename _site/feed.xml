<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://bluesplatter.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bluesplatter.com/" rel="alternate" type="text/html" /><updated>2022-11-18T16:23:46+09:00</updated><id>https://bluesplatter.com/feed.xml</id><title type="html">Bluesplatter</title><subtitle>전문적이지 않은 정보들, 감상, 즉흥적인 내용들</subtitle><author><name>HY03</name><email>hyunik03@gmail.com</email></author><entry><title type="html">Sequences, Time Series and Prediction - 04. Real-world time series data</title><link href="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_04_Real-world_time_series_data/" rel="alternate" type="text/html" title="Sequences, Time Series and Prediction - 04. Real-world time series data" /><published>2022-11-07T14:00:00+09:00</published><updated>2022-11-07T14:00:00+09:00</updated><id>https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_04_Real-world_time_series_data</id><content type="html" xml:base="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_04_Real-world_time_series_data/">&lt;h1 id=&quot;real-world-time-series-data&quot;&gt;Real-world time series data&lt;/h1&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;실사용 데이터 (태양의 흑점활동) 이용하기&lt;/li&gt;
  &lt;li&gt;Conv1D, LSTM, DNN 을 결합한 모델을 활용할 것&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convolutions&quot;&gt;Convolutions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      model = tf.keras.models.Sequential([
          tf.keras.layers.Conv1D(filters=32, kernel_size=5, // 32개의 필터를 학습할 1D Conv
                              strides=1, padding=&quot;casual&quot;,
                              activation=&quot;relu&quot;,
                              input_shape=[None, 1]),
          tf.keras.layers.LSTM(32, return_sequences=True),
          tf.keras.layers.LSTM(32),
          tf.keras.layers.Dense(1),
          tf.keras.layers.Lambda(lambda x: x * 200)
      ])

      optimizer = tf.keras.optimizers.SGD(learning_late=1e-5, momentum=0.9)

      model.compile(loss=tf.keras.losses.Huber(),
                  optimizer=optimizer,
                  metrics=[&quot;mae&quot;])

      model.fit(dataset, epochs=500)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bi-directional-lstms&quot;&gt;Bi-directional LSTMs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      model = tf.keras.models.Sequential([
          tf.keras.layers.Conv1D(filters=32, kernel_size=5, 
                              strides=1, padding=&quot;casual&quot;,
                              activation=&quot;relu&quot;,
                              input_shape=[None, 1]), // LSTM 의 입력값을 재구성하는 Lambda 레이어를 없앰
          tf.keras.layers.LSTM(32, return_sequences=True),
          tf.keras.layers.LSTM(32),
          tf.keras.layers.Dense(1),
          tf.keras.layers.Lambda(lambda x: x * 200)
      ])

      optimizer = tf.keras.optimizers.SGD(learning_late=1e-5, momentum=0.9) // 플로팅한 결과 불안정해지기 전의 학습률

      model.compile(loss=tf.keras.losses.Huber(),
                  optimizer=optimizer,
                  metrics=[&quot;mae&quot;])

      model.fit(dataset, epochs=500) // epoch 늘리기
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;windowed_dataset 헬퍼 함수&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      def windowed_dataset(series, window_size, batch_size, shuffle_buffer):

          ds = tf.data.Dataset.from_tensor_slices(series)
          ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
          ds = ds.flat_map(lambda w: w.batch(window_size + 1))
          ds = ds.shuffle(shuffle_buffer)
          ds = ds.map(lambda w: (w[:-1], w[-1]))

          return ds.batch(batch_size).prefetch(1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bi-directional LSTM&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      model = tf.keras.models.Sequential([
          tf.keras.layers.Conv1D(filters=32, kernel_size=5, 
                              strides=1, padding=&quot;casual&quot;,
                              activation=&quot;relu&quot;,
                              input_shape=[None, 1]), 
          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)), // 양방향
          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
          tf.keras.layers.Dense(1),
          tf.keras.layers.Lambda(lambda x: x * 200)
      ])

      optimizer = tf.keras.optimizers.SGD(learning_late=1e-5, momentum=0.9) // 플로팅한 결과 불안정해지기 전의 학습률

      model.compile(loss=tf.keras.losses.Huber(),
                  optimizer=optimizer,
                  metrics=[&quot;mae&quot;])

      model.fit(dataset, epochs=500)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;결과수치는 긍정적이나 검증세트에 예측을 플로팅 해보면 과적합이 보여 일부 파라미터에 변화를 줄 필요가 있음&lt;/li&gt;
      &lt;li&gt;MAE 로 손실을 플로팅하면 문제점을 확인할 수 있음
        &lt;ul&gt;
          &lt;li&gt;스파이크 현상은 배치 크기가 작아서 무작위 노이즈가 많기 때문임&lt;/li&gt;
          &lt;li&gt;배치사이즈를 줄이거나 늘이는 것에 따라 학습과 예측이 달라짐&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;more-on-batch-sizing&quot;&gt;More on batch sizing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;신경망을 더 빠르게 학습하도록 하는 최적화 알고리즘
    &lt;ul&gt;
      &lt;li&gt;머신러닝 : 잘 작동되는 모델을 찾기 위해 많은 훈련을 거쳐야 하는 반복적인 과정
        &lt;ul&gt;
          &lt;li&gt;모델을 빠르게 훈련시키는 것이 매우 중요함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;딥러닝은 빅데이터에서 가장 잘 작동됨 -&amp;gt; 훈련이 어려움 (큰 데이터 세트에서 훈련하는 것은 매우 느린과정)&lt;/li&gt;
      &lt;li&gt;좋은 최적화 알고리즘을 찾는 것은 효율성을 향상시켜준다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;미니배치 경사 하강법
    &lt;ul&gt;
      &lt;li&gt;벡터화 : m개의 샘플에 대한 계산을 효율적으로 만들어줌. 명시적인 반복문 없이도 훈련 세트를 진행할 수 있도록 함.&lt;/li&gt;
      &lt;li&gt;훈련 샘플을 받아서 큰 벡터에 저장함
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X = [x^1, x^2, ..., x^m]&lt;/code&gt; : shape : (n_x,m)&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Y = [y^1, y^2, ..., y^m]&lt;/code&gt; : shape : (1,m)&lt;/li&gt;
          &lt;li&gt;하지만 m 의 수치가 크면 여전히 학습은 느리다.&lt;/li&gt;
          &lt;li&gt;예를들어 m 의 수치가 500만 이라면?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;전체 훈련 세트에 대한 경사 하강법을 구현하면 경사 하강법의 작은 한 단계를 밟기 전에 모든 훈련 세트를 처리해야 함
        &lt;ul&gt;
          &lt;li&gt;즉, 경사하강법의 다음 단계를 밟기 전에 500만 개의 전체 훈련 샘플을 처리해야 함&lt;/li&gt;
          &lt;li&gt;500만 개의 전체 훈련 샘플을 모두 훈련하기 전에 경사 하강법이 진행되도록 하면 더 빠른 알고리즘을 얻을 수 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;훈련 세트를 더 작은 훈련세트 (미니배치) 로 나눔
        &lt;ul&gt;
          &lt;li&gt;mini-batch 가 1000개의 샘플을 갖는다고 가정&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X = [x^1, x^2, ..., x^1000 | x^1001, ..., x^2000 | ... | ... x^m]&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X = X^{1},                   X^{2}, ... ,               X^{5000}&lt;/code&gt; : shape : (n_x, 1000)&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Y = Y^{1},                   Y^{2}, ... ,               Y^{5000}&lt;/code&gt; : shape : (1, 1000)&lt;/li&gt;
          &lt;li&gt;Mini-batch t : X^{t}, Y^{t}&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;표기법 정의
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x^(i)&lt;/code&gt; : i 번째 훈련 샘플&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z^[l]&lt;/code&gt; : l 번째 신경망의 z 값&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X^{t}&lt;/code&gt; : t 번째 미니배치 X&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Batch Gradient Descent : 일반적인 경사하강법, 모든 훈련 세트를 동시에 훈련시킴, 훈련 샘플의 모든 배치를 진행시킨다는 관점&lt;/li&gt;
      &lt;li&gt;미니배치 : 전체 훈련 세트 X,Y 를 한번에 진행시키지 않고, 하나의 미니배치 X^{t}, Y^{t} 를 동시에 진행시키는 알고리즘
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  for t=1 ,..., 5000 : 총 미니배치의 수 (5000개)
      // 1 step of gradient descent using X^{t}, Y^{t}
      // (as if m=1000)
      // 모든 1000개의 샘플에 대해 명시적인 반복문을 갖는 것보다 벡터화를 사용해 모든 1000개의 샘플을 동시에 진행함
      Forward prop on X^{t}
          Z^[1] = W^[1] * X^{t} + b^[1] : Vectorized Implementation (1000 examples)
          A^[1] = g^[1] * (Z^[1]) : Vectorized Implementation (1000 examples)
          ...
          A^[l] = g^[l] * (Z^[l]) : Vectorized Implementation (1000 examples)
      Compute cost J^{t} = 1/1000 * Sum (( i = 1 to l) Loss(expect(y^(i)), y^(i)))
          + 정규화 항
      Backprop to compute Gradients cost J^(t) using X^{t}, Y^{t}
          W^[l] = W^[l] - adW^[l], b^[l] = b^[l] - adb^[l]
      ...
      1 epoch : pass through training set (5000 개의 경사하강단계)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convolutions-with-lstm-notebook&quot;&gt;Convolutions with LSTM notebook&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convolutions-with-lstm&quot;&gt;Convolutions with LSTM&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;real-data---sunspots&quot;&gt;Real data - sunspots&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;소스 내려받기 : 케글에서 내려받거나, 이번학습을 위한 데이터 제공 저장소를 사용 (후자)&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/Sunspots.csv -O /tmp/sunspots.csv&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;CSV 읽기&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      import csv
      time_step = []
      sunspots = []

      with open(&apos;/tmp/sunspots.csv&apos;) as csvfile:
          reader = csv.reader(csvfile, delimiter=&apos;,&apos;)
          next(reader)
          for row in reader :
              sunspots.append(float(row[2]))
              time_step.append(int(row[0]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;numpy 배열로 전환&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      series = np.array(sunspots) // numpy 에 항목을 추가할 때마다 목록을 복제하는데,
      time = np.array(time_step) // 메모리 관리 과정이 많이 진행되기 때문에 데이터 양이 많으면 느려질 수 있음
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;시계열을 훈련 및 검증 데이터 세트로 분할&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      split_time = 1000
      time_train = time[:split_time]
      x_train = series[:split_time]
      time_valid = time[split_time:]
      x_valid = series[split_time:]

      window_size = 20
      batch_size = 32
      shuffle_buffer_size = 1000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이전 windowed_dataset 함수와 동일 코드를 사용&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
          dataset = tf.data.Dataset.from_tensor_slices(series)
          dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
          dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
          dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))
          dataset = dataset.batch(batch_size).prefetch(1)
          return dataset
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;train-and-tune-the-model&quot;&gt;Train and tune the model&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;이전 수업에서 배웠던 모델로 예측하여 플로팅하면, 결과는 괜찮아보이나 MAE 가 매우 큼&lt;/li&gt;
  &lt;li&gt;이는 이전 window_size 가 20 (여기서는 약 2년이 안되는 시간) 이나, 사실 흑점 데이터의 주기는 11년 혹은 22년으로 추정됨&lt;/li&gt;
  &lt;li&gt;window_size 를 11년에 해당하는 132로 두고 다시 훈련을 하면 차트는 더 잘 나오나 MAE는 더 커짐
    &lt;ul&gt;
      &lt;li&gt;데이터를 되돌아보면 11년 주기의 계절성을 갖지만 창 안에 계절 전체가 있어야 할 필요는 없음&lt;/li&gt;
      &lt;li&gt;플롯을 확대해보면 전형적인 시계열 형태 데이터임&lt;/li&gt;
      &lt;li&gt;나중에 오는 값이 앞선 값과 연관이 있지만 노이즈가 많음&lt;/li&gt;
      &lt;li&gt;그래서 훈련 시에 창 크기가 클 필요는 없을 수도 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data 의 분할을 1000을 훈련, 2500을 검증으로 설정하였는데 이는 좋지 못한 분할임
    &lt;ul&gt;
      &lt;li&gt;3500과 500으로 지정&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;신경망 설계와 파라미터의 크기 변경
    &lt;ul&gt;
      &lt;li&gt;10, 10, 1 레이어 를 30, 15, 1 로 값을 바꿔서 훈련 (입력 Shape 값이 30)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;prediction&quot;&gt;Prediction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;예측
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.predict(series[3205:3235][np.newaxis])&lt;/code&gt; : 7.077 개의 흑점 예상 (실 데이터 8.7 개)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;설정 변경 : MAE 13.7&lt;/p&gt;
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  split_time = 3000
  window_size = 60
	
  model = tf.keras.models.Sequential([
      tf.keras.layers.Dense(20, input_shape=[window_size], activation=&quot;relu&quot;),
      tf.keras.layers.Dense(10, activation=&quot;relu&quot;),
      tf.keras.layers.Dense(1)
  ])
	
  model.compile(loss=&quot;mse&quot;, optimizer=tf.keras.optimizers.SGD(lr=1e-7, momentum=0.9))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;8.13 예측 (실제값 8.7)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sunspots-notebooks-lab-2--lab-3&quot;&gt;Sunspots notebooks (Lab 2 &amp;amp; Lab 3)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 으로 대체&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sunspots&quot;&gt;Sunspots&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;입력 창의 크기를 60으로 함&lt;/li&gt;
  &lt;li&gt;DNN 을 Dense 20, 10, 1 로 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;combining-our-tools-for-analysis&quot;&gt;Combining our tools for analysis&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      window_size = 60
      batch_size = 64
      train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)

      model = tf.keras.models.Sequential([
          tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=&quot;casual&quot;, activation=&quot;relu&quot;, input_shape=[None, 1]),
          tf.keras.layers.LSTM(32, return_sequences=True),
          tf.keras.layers.LSTM(32),
          tf.keras.layers.Dense(30, activation=&quot;relu&quot;),
          tf.keras.layers.Dense(10, activation=&quot;relu&quot;),
          tf.keras.layers.Dense(1),
          tf.keras.layers.Lambda(lambda x: x * 400)
      ])

      lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-5 * 10**(epoch / 20))
      optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-8, momentum=0.9)
      model.compile(loss=tf.keras.losses.Huber(), optimizer = optimizer, metrics=[&quot;mae&quot;])
      history = model.fit(train-set, epochs=100, callbacks=[lr_schedule])

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;batch_size 의 변경 (256) : loss 에 노이즈가 생길 경우 고려해볼 파라미터&lt;/li&gt;
  &lt;li&gt;하이퍼파라미터를 다양하게 실험해 봐야 함&lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="AI" /><category term="Time Series" /><category term="Coursera" /><category term="deeplearning.ai" /><category term="Laurence Moroney" /><category term="timeseries" /><category term="시계열" /><category term="tensorflow" /><summary type="html">Real-world time series data</summary></entry><entry><title type="html">Sequences, Time Series and Prediction - 03. Recurrent Neural Networks for Time Series</title><link href="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_03_Recurrent_Neural_Networks_for_Time_Series/" rel="alternate" type="text/html" title="Sequences, Time Series and Prediction - 03. Recurrent Neural Networks for Time Series" /><published>2022-10-25T14:00:00+09:00</published><updated>2022-10-25T14:00:00+09:00</updated><id>https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_03_Recurrent_Neural_Networks_for_Time_Series</id><content type="html" xml:base="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_03_Recurrent_Neural_Networks_for_Time_Series/">&lt;h1 id=&quot;recurrent-neural-networks-for-time-series&quot;&gt;Recurrent Neural Networks for Time Series&lt;/h1&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Recurrent Neural Networks 와 Long Short Term Memory Networks 는 시계열 데이터의 예측과 분류에 매우 유용함&lt;/li&gt;
  &lt;li&gt;Lambda Layer : 신경망 내 임의의 코드를 레이어로 활용할 수 있음 (전처리와 후처리)
    &lt;ul&gt;
      &lt;li&gt;명시적인 전처리 단계로 데이터를 스케일링한 다음 신경망에 넣는 게 아니라 Lambda 레이어를 사용할 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conceptual-overview&quot;&gt;Conceptual overview&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;RNN : 순환 레이어를 포함한 신경망
    &lt;ul&gt;
      &lt;li&gt;시퀀스 입력값을 순차적으로 처리하도록 설계&lt;/li&gt;
      &lt;li&gt;입력값의 형태 : 배치 사이즈, 타임스탬프 (윈도우사이즈), 컬럼디멘전 (다변량) = 3차원
        &lt;ul&gt;
          &lt;li&gt;지금까지 사용한 입력값 형태 : 배치 사이즈, 입력값 특징 수 (윈도우 사이즈)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RNN Cell
    &lt;ul&gt;
      &lt;li&gt;겉으로 보기에는 셀이 많은 것 같지만, 셀은 하나 뿐이고 이를 반복적으로 사용하여 출력값을 산출&lt;/li&gt;
      &lt;li&gt;입력값이 2개 (X 값과 상태벡터 H 값) - 상태벡터값을 이용해 이전 입력값의 잔존 데이터를 전달받음&lt;/li&gt;
      &lt;li&gt;입력차원 (예: 타임스탬프가 30개) 만큼 반복&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rnn-notebook&quot;&gt;RNN Notebook&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;shape-of-the-inputs-to-the-rnn&quot;&gt;Shape of the inputs to the RNN&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;데이터의 형태, 데이터를 분할한 배치
    &lt;ul&gt;
      &lt;li&gt;예시
        &lt;ul&gt;
          &lt;li&gt;Window size 가 30 : 시간 단계가 30&lt;/li&gt;
          &lt;li&gt;4개로 일괄 처리 : 배치값 4&lt;/li&gt;
          &lt;li&gt;입력 형태는 4 * 30 * 1&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;셀의 관점
        &lt;ul&gt;
          &lt;li&gt;하나의 셀은 고정된 시간 단계에서 (Batch Size : 4 * 1) 의 입력을 받음&lt;/li&gt;
          &lt;li&gt;레이어 내 메모리셀이 3개의 뉴런으로 구성된다면&lt;/li&gt;
          &lt;li&gt;출력값 행렬은 4 * 3&lt;/li&gt;
          &lt;li&gt;출력 형태는 4(Batch Size) * 30(Window Size) * 3(Unit Size)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;단순 RNN 에서의 상태 출력값 H 는 출력값 행렬 Y 와 동일함&lt;/li&gt;
      &lt;li&gt;일부 경우에는 시퀀스를 입력하되, 출력값의 경우 배치 내 각 인스턴스에 대한 단일 벡터를 얻고 싶은 경우가 있음
        &lt;ul&gt;
          &lt;li&gt;마지막 (마지막 시퀀스 스텝-Window) 을 제외하고 모든 출력값을 무시&lt;/li&gt;
          &lt;li&gt;시퀀스 출력값을 도출하려면 레이어를 생성할 때 return_sequences 를 True 로 지정해야 함
            &lt;ul&gt;
              &lt;li&gt;하나의 RNN 레이어를 다른 레이어 위에 스태킹 할때 이 작업이 반드시 필요&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;outputting-a-sequence&quot;&gt;Outputting a sequence&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;적층 예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  model = tf.keras.models.Sequential([
	tf.keras.layers.SimpleRNN(40, return_sequences=True, input_shape = [None,1]),
	tf.keras.layers.SimpleRNN(40),
	tf.keras.layers.Dense(1),
  ])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;타 RNN 레이어에 입력으로 들어가야 하는 RNN 레이어에 return_sequences 를 True 로 설정&lt;/li&gt;
      &lt;li&gt;Dense 레이어에 입력으로 들어가야 하는 RNN 레이어는 마지막 시퀀스 단계의 결과값만을 출력&lt;/li&gt;
      &lt;li&gt;input_shape (배치 사이즈) 를 설정하지 않음 : 어떤 크기든 상관이 없으니 정의할 필요가 없음&lt;/li&gt;
      &lt;li&gt;Timestamp 값을 None 으로 설정 : 시퀀스 길이와 관계 없이 입력값을 받음&lt;/li&gt;
      &lt;li&gt;마지막 차원이 1로 되어있는 이유 : 일변량 시계열을 다루기 때문&lt;/li&gt;
      &lt;li&gt;두번째 층 RNN 레이어에 return_sequences 값을 True 로 설정할 경우
        &lt;ul&gt;
          &lt;li&gt;시퀀스 값이 출력됨&lt;/li&gt;
          &lt;li&gt;Keras 는 각 시간 단계별로 동일한 Dense 레이어를 독립적으로 활용함&lt;/li&gt;
          &lt;li&gt;입력값이 시퀀스이고 출력값 또한 시퀀스일 경우 : 시퀀스 to 시퀀스 RNN&lt;/li&gt;
          &lt;li&gt;차원의 값은 RNN 레이어의 유닛 값에 따라 변동될 수 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lambda-layers&quot;&gt;Lambda layers&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  model = tf.keras.models.Sequential([
    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),
                        input_shape=[window_size]),
    tf.keras.layers.SimpleRNN(40, return_sequences=True),
    tf.keras.layers.SimpleRNN(40),
    tf.keras.layers.Dense(1),
    tf.keras.layers.Lambda(lambda x: x * 100.0)
  ])	
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;첫 lambda 레이어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.expand_dims(x, axis=-1)&lt;/code&gt; : 기존 window 생성 function 을 그대로 활용하기 위해 차원을 하나 늘림 (2차원-&amp;gt;3차원)&lt;/li&gt;
      &lt;li&gt;마지막 lambda 레이어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lambda x: x * 100.0&lt;/code&gt; : RNN 의 기본 활성함수 tanh 의 출력값 -1 ~ 1 &amp;gt; 시계열 값은 10개 단위로 구성되고, 비슷한 값으로 출력값을 올리면 학습에 도움이 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;adjusting-the-learning-rate-dynamically&quot;&gt;Adjusting the learning rate dynamically&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  train_set = windowed_dataset(x_train, window_size, batch_size=128,
      shuffle_buffer=shuffle_buffer_size)

  model = tf.keras.models.Sequential([
          tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1), input_shape=[None]),
          tf.keras.layers.SimpleRNN(40, return_sequences=True),
          tf.keras.layers.SimpleRNN(40),
          tf.keras.layers.Dense(1),
          tf.keras.layers.Lambda(lambda x: x * 100.0)
      ])

  lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))

  optimizer = tf.keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9)

  model.compile(loss=tf.kears.losses.Huber(),
                  optimizer=optimizer,
                  metrics=[&quot;mae&quot;])

  history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;callback 함수를 활용, epoch 진행 별로 학습률을 약간 변경&lt;/li&gt;
      &lt;li&gt;Huber 손실함수 : 이상치에 덜 민감하게 반응하는 손실함수, 데이터에 노이즈가 많이 섞여있을 때 시도해볼만 함
        &lt;ul&gt;
          &lt;li&gt;squared error loss 보다 이상치에 덜 민감함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lstm&quot;&gt;LSTM&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;RNN
    &lt;ul&gt;
      &lt;li&gt;X 가 셀에 투입되면 Y 결과값과 H 상태벡터가 출력되고, 이는 다음 셀에 영향을 줌&lt;/li&gt;
      &lt;li&gt;Step 이 진행되면서 초기 H 상태벡터의 영향도는 점점 작아짐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;LSTM
    &lt;ul&gt;
      &lt;li&gt;전체 훈련 기간 동안 상태를 유지해주는 셀 상태를 추가함&lt;/li&gt;
      &lt;li&gt;상태 값이 셀 간에 이동을 하고 Step 사이를 이동하면서 더 잘 유지될 수 있게함 - 앞 단계에 있던 데이터가 전체 추정치에 더 큰 영향을 줌&lt;/li&gt;
      &lt;li&gt;상태는 양방향으로 움직일 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;coding-lstms&quot;&gt;Coding LSTMs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  tf.keras.backend.clear_session()
  dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)

  model = tf.keras.models.Sequential([
      tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[None]),
      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
      tf.keras.layers.Dense(1),
      tf.keras.layers.Lambda(lambda x: x * 100.0)
  ])	

  model.compile(loss=&quot;mse&quot;, optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))
  model.fit(dataset, epochs=100, verbose=0)
	
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.keras.backend.clear_session()&lt;/code&gt; : 내부 변수를 초기화. 이후 버전에 영향을 주지 않고 여러 모델을 시험해 볼 수 있음&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))&lt;/code&gt; : 32개 셀의 단일 LSTM 레이어 추가. 예측에 미치는 영향을 파악할 수 있도록 양방향으로 만듦&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;예시&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  tf.keras.backend.clear_session()
  dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)

  model = tf.keras.models.Sequential([
      tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[None]),
      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),
      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
      tf.keras.layers.Dense(1),
      tf.keras.layers.Lambda(lambda x: x * 100.0)
  ])	

  model.compile(loss=&quot;mse&quot;, optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))
  model.fit(dataset, epochs=100, verbose=0)
	
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True))&lt;/code&gt; : LSTM 레이어를 한층 더 쌓음, retrun_sequences 를 True 로 설정해야만 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="AI" /><category term="Time Series" /><category term="Coursera" /><category term="deeplearning.ai" /><category term="Laurence Moroney" /><category term="timeseries" /><category term="시계열" /><category term="tensorflow" /><summary type="html">Recurrent Neural Networks for Time Series</summary></entry><entry><title type="html">Sequences, Time Series and Prediction - 02. Deep Neural Networks for Time Series</title><link href="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_02_Deep_Neural_Networks_for_Time_Series/" rel="alternate" type="text/html" title="Sequences, Time Series and Prediction - 02. Deep Neural Networks for Time Series" /><published>2022-10-21T14:00:00+09:00</published><updated>2022-10-21T14:00:00+09:00</updated><id>https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_02_Deep_Neural_Networks_for_Time_Series</id><content type="html" xml:base="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_02_Deep_Neural_Networks_for_Time_Series/">&lt;h1 id=&quot;deep_neural_networks_for_time_series&quot;&gt;Deep_Neural_Networks_for_Time_Series&lt;/h1&gt;

&lt;h2 id=&quot;preparing-features-and-labels&quot;&gt;Preparing features and labels&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;시계열에서의 Input 값과 Label 값
    &lt;ul&gt;
      &lt;li&gt;Features : 입력되는 값
        &lt;ul&gt;
          &lt;li&gt;예 : 이전 30개의 시점의 값&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Labels : 예측할 값 (정답)
        &lt;ul&gt;
          &lt;li&gt;예 : 미래 시점의 값&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)
	dataset = tf.data.Dataset.range(10)

	# Window the data but only take those with the specified size
	dataset = dataset.window(5, shift=1, drop_remainder=True)

	# Flatten the windows by putting its elements in a single batch
	dataset = dataset.flat_map(lambda window: window.batch(5))

	# Create tuples with features (first four elements of the window) and labels (last element)
	dataset = dataset.map(lambda window: (window[:-1], window[-1]))

	# Shuffle the windows
	dataset = dataset.shuffle(buffer_size=10)

	# Create batches of windows ( 한번에 여러 데이터 처리를 위함 )
	dataset = dataset.batch(2).prefetch(1)

	# Print the results
	for x,y in dataset:
	  print(&quot;x = &quot;, x.numpy())
	  print(&quot;y = &quot;, y.numpy())
	  print()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;feeding-windowed-dataset-into-neural-network&quot;&gt;Feeding windowed dataset into neural network&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
	    &quot;&quot;&quot;Generates dataset windows

	    Args:
	      series (array of float) - contains the values of the time series
	      window_size (int) - the number of time steps to include in the feature
	      batch_size (int) - the batch size
	      shuffle_buffer(int) - buffer size to use for the shuffle method

	    Returns:
	      dataset (TF Dataset) - TF Dataset containing time windows
	    &quot;&quot;&quot;
	  
	    # Generate a TF Dataset from the series values
	    dataset = tf.data.Dataset.from_tensor_slices(series)
	    
	    # Window the data but only take those with the specified size
	    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
	    
	    # Flatten the windows by putting its elements in a single batch
	    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))

	    # Create tuples with features and labels 
	    dataset = dataset.map(lambda window: (window[:-1], window[-1]))

	    # Shuffle the windows 
	    dataset = dataset.shuffle(shuffle_buffer) // shuffle buffer 의 크기만큼 이동하면서 buffer 내에서 무작위로 하나씩 선택 (선택속도증가)
	    
	    # Create batches of windows
	    dataset = dataset.batch(batch_size).prefetch(1)
	    
	    return dataset
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;single-layer-neural-network&quot;&gt;Single layer neural network&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	# Generate the dataset windows
	dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)

	# Build the single layer neural network
	l0 = tf.keras.layers.Dense(1, input_shape=[window_size])
	model = tf.keras.models.Sequential([l0])

	# Print the initial layer weights
	print(&quot;Layer weights: \n {} \n&quot;.format(l0.get_weights()))

	# Print the model summary
	model.summary()

	# Set the training parameters
	model.compile(loss=&quot;mse&quot;, optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))

	# Train the model
	model.fit(dataset,epochs=100)

	# Print the layer weights
	print(&quot;Layer weights {}&quot;.format(l0.get_weights()))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;machine-learning-on-time-windows&quot;&gt;Machine learning on time windows&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;prediction&quot;&gt;Prediction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;more-on-single-layer-neural-network&quot;&gt;More on single layer neural network&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-neural-network-training-tuning-and-prediction&quot;&gt;Deep neural network training, tuning and prediction&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
	dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
	model = tf.keras.models.Sequential([
		tf.keras.layers.Dense(10, input_shape=[window_size], activation=&quot;relu&quot;)
		tf.keras.layers.Dense(10, activation=&quot;relu&quot;)
		tf.keras.layers.Dense(1)
	])

	model.compile(loss=&quot;mse&quot;, optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))
	model.fit(dataset, epochs=100, verbose=0)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;우리가 선택한 학습률이 아니라 최적의 학습률을 선택할 수 있다면 더 좋은 결과가 나올 것
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;callback 을 활용하는 기법&lt;/p&gt;

        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		
      dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
      model = tf.keras.models.Sequential([
          tf.keras.layers.Dense(10, input_shape=[window_size], activation=&quot;relu&quot;)
          tf.keras.layers.Dense(10, activation=&quot;relu&quot;)
          tf.keras.layers.Dense(1)
      ])
		
      // 각 epoch 종료 시마다 callback 에서 호출, epoch 숫자값을 기준으로 학습률을 값으로 변경
      // 
      lr_schedule = tf.keras.callbacks.LearningRateScheduler(
          lambda epoch: 1e-8 * 10**(epoch / 20))
		
      optimizer = tf.keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9)
		
      model.compile(loss=&quot;mse&quot;, optimizer=optimizer)
			
      history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])
		
      // 트레이닝을 마치고 나면 epoch 당 학습률에 대한 epoch 당 오차를 플로팅
      // x 축은 learning rate, y축은 epoch 의 손실
      lrs = 1e-8 (10 ** (np.arange(100) / 20))
      plt.semilogx(lrs, history.history[&quot;loss&quot;])
      plt.axis([1e-8, 1e-3, 0, 300])
		
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;위에서 구한 learning_rate (7e-6) 로 재훈련&lt;/p&gt;

        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
      window_size = 30
      dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
      model = tf.keras.models.Sequential([
          tf.keras.layers.Dense(10, input_shape=[window_size], activation=&quot;relu&quot;)
          tf.keras.layers.Dense(10, activation=&quot;relu&quot;)
          tf.keras.layers.Dense(1)
      ])

      optimizer = tf.keras.optimizers.SGD(learning_rate=7e-6, momentum=0.9)
      model.compile(loss=&quot;mse&quot;, optimizer=optimizer)
      model.fit(dataset, epochs=500)

      // 훈련 도중 산출한 손실 플로팅 코드
      loss = history.history[&apos;loss&apos;]
      epochs = range(len(loss))
      plt.plot(epochs, loss, &apos;b&apos;, label=&apos;Training Loss&apos;)
      plt.show()

      // 초기손실 (왜곡값) 자르기
      loss = history.history[&apos;loss&apos;]
      epochs = range(10, len(loss))
      plot_loss = loss[10:]
      print(plot_loss)
      plt.plot(epochs, plot_loss, &apos;b&apos;, label=&apos;Training Loss&apos;)
      plt.show()

      // mean absolute error 값 확인
      tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-neural-network&quot;&gt;Deep neural network&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 참조&lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="AI" /><category term="Time Series" /><category term="Coursera" /><category term="deeplearning.ai" /><category term="Laurence Moroney" /><category term="timeseries" /><category term="시계열" /><category term="tensorflow" /><summary type="html">Deep_Neural_Networks_for_Time_Series</summary></entry><entry><title type="html">Sequences, Time Series and Prediction - 01. Sequences and Prediction</title><link href="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_01_Sequences_and_Prediction/" rel="alternate" type="text/html" title="Sequences, Time Series and Prediction - 01. Sequences and Prediction" /><published>2022-10-20T14:00:00+09:00</published><updated>2022-10-20T14:00:00+09:00</updated><id>https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_01_Sequences_and_Prediction</id><content type="html" xml:base="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_01_Sequences_and_Prediction/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;순차 시계열 데이터 (Sequential time series data)
    &lt;ul&gt;
      &lt;li&gt;값이 시간에 따라 변하는 것&lt;/li&gt;
      &lt;li&gt;예
        &lt;ul&gt;
          &lt;li&gt;주식거래의 종가&lt;/li&gt;
          &lt;li&gt;특정 일의 기온&lt;/li&gt;
          &lt;li&gt;웹사이트의 방문자 수&lt;/li&gt;
          &lt;li&gt;스프레드시트에 기록할 수 있는 데이터&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;다룰 내용
    &lt;ul&gt;
      &lt;li&gt;미래 시점의 값 예측을 위한 다양한 방법론&lt;/li&gt;
      &lt;li&gt;위의 내용의 구현법&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction-a-conversation-with-andrew-ng&quot;&gt;Introduction, A conversation with Andrew Ng&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;데이터의 합성 시퀀스를 만들기&lt;/li&gt;
  &lt;li&gt;데이터 시계열에서 공통 속성을 살펴보기
    &lt;ul&gt;
      &lt;li&gt;계절성 : 날씨의 경우 6월이 1월보다 따듯하고, 11월은 10월보다 습할 수 있음&lt;/li&gt;
      &lt;li&gt;경향성 : 주식의 종가처럼 시간이 가면서 상승, 혹은 하강&lt;/li&gt;
      &lt;li&gt;노이즈 : 무작위 요소&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;구현 : 흑점 활동 모니터
    &lt;ul&gt;
      &lt;li&gt;흑점 활동
        &lt;ul&gt;
          &lt;li&gt;11년, 혹은 22년의 주기 (계절성)&lt;/li&gt;
          &lt;li&gt;노이즈&lt;/li&gt;
          &lt;li&gt;250년 전부터 측정해온 데이터 활용&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;sequences-and-prediction&quot;&gt;Sequences and Prediction&lt;/h1&gt;

&lt;h2 id=&quot;time-series-examples&quot;&gt;Time series examples&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;시계열 (Time Series) 이란 무엇인가?
    &lt;ul&gt;
      &lt;li&gt;오랜 시간에 걸쳐 균등한 간격으로 순서가 지정된 시퀀스로 나타나는 값&lt;/li&gt;
      &lt;li&gt;다변량 시계열 : 각 시점에서 복수 개의 값이 표시된 경우
        &lt;ul&gt;
          &lt;li&gt;데이터에 추가값을 더하여 상관관계를 파악할 수 있음
            &lt;ul&gt;
              &lt;li&gt;시간의 흐름에 따른 기온과 이산화탄소 배출량의 상관관계&lt;/li&gt;
              &lt;li&gt;자동차의 이동경로 (동시간의 간격 (속도), 위도, 경도 등)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;machine-learning-applied-to-time-series&quot;&gt;Machine learning applied to time series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;머신러닝으로 가능한 시계열 관련 작업
    &lt;ul&gt;
      &lt;li&gt;데이터를 기반으로 한 예측 작업&lt;/li&gt;
      &lt;li&gt;이미 가지고 있는 데이터보다 이전 시점의 데이터를 예측&lt;/li&gt;
      &lt;li&gt;실질적으로 존재하지 않는 데이터의 시점의 데이터를 예측&lt;/li&gt;
      &lt;li&gt;변칙 감지에 활용&lt;/li&gt;
      &lt;li&gt;패턴의 발견 (예: 음파를 인식)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;common-patterns-in-time-series&quot;&gt;Common patterns in time series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;흔하게 나타나는 시계열 패턴 (눈으로 보고 인식하는데 유용)
    &lt;ul&gt;
      &lt;li&gt;추세 : 특정한 방향으로 움직이는 경우 (예: 무어의 법칙)&lt;/li&gt;
      &lt;li&gt;계절성 : 패턴이 예측 가능한 간격으로 반복됨 (예: 쇼핑사이트 방문자수 (주말에 올라감))&lt;/li&gt;
      &lt;li&gt;노이즈 : 전혀 예측이 불가능한 임의의 값들로 구성된 세트&lt;/li&gt;
      &lt;li&gt;자기상관관계 : 시간의 흐름에 따라 과거 혹은 현재의 값이 미래에 영향을 주는 것&lt;/li&gt;
      &lt;li&gt;복합적으로 나타나는 경우&lt;/li&gt;
      &lt;li&gt;비정상시계열 : 명확한 패턴을 보이다가 큰 이벤트로 인해 패턴이 깨지는 경우
        &lt;ul&gt;
          &lt;li&gt;특정 경향성을 보이는 경우에 특정 구간만 학습&lt;/li&gt;
          &lt;li&gt;하지만 현실의 데이터는 단순하지 않음 (패턴이 깨지며 경향이 나타났으나 다시 과거 패턴으로 회귀)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction-to-time-series&quot;&gt;Introduction to time series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Colab 파일&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;train-validation-and-test-sets&quot;&gt;Train, validation and test sets&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;예측 모델의 성능 측정
    &lt;ul&gt;
      &lt;li&gt;Fixed Partitioning (고정 파티셔닝) : 시계열을 훈련기간, 검증 기간, 테스트 기간으로 분할
        &lt;ul&gt;
          &lt;li&gt;시계열이 계절성이 있는 경우 각각의 기간에 계절 전체를 포함하고 싶음&lt;/li&gt;
          &lt;li&gt;시간이 지남에 따라 검증 기간의 데이터를 훈련에 사용, 테스트 기간의 데이터로 검증을 하고, 새로운 테스트 기간으로 테스트를 함&lt;/li&gt;
          &lt;li&gt;테스트 기간은 현재 데이터에 가장 영향을 많이 줄 수 있는 데이터. 따라서 테스트 세트를 포기하는 경우가 흔함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;롤 포워드 파티셔닝
        &lt;ul&gt;
          &lt;li&gt;짧은 훈련기간을 가지고, 점점 증가시켜 (한번에 하루, 한번에 한 주) 반복수행&lt;/li&gt;
          &lt;li&gt;검증기간에는 다음 달이나 다음 주를 예측&lt;/li&gt;
          &lt;li&gt;고정 파티셔닝을 여러 번 시행하고 모델을 계속 다듬는 과정&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;metrics-for-evaluating-performance&quot;&gt;Metrics for evaluating performance&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;성능을 계산할 지표
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      errors = forcasts - actual // 오차산출
      mse = np.square(errors).mean() // 평균제곱오차 :  가장 일반적인 지표 (음수제거를 하여 에러간 상쇄가 없도록 함)
      rmse = np.sqrt(mse) // 평균제곱근오차 : 원래 에러 규모와 동일한 규모를 만들기 위해 제곱근 계
      mae = np.abs(errors).mean() // 평균절대오(편)차 :  제곱 대신 절대값을 사용
      mape = np.abs(errors / x valid).mean() // 평균절대백분율오차 : 절대 오차와 절대값의 평균 비율 (값 대비 오차의 크기를 파악)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;작은 오차보다 큰 오차가 생겼을 경우 비용이 훨씬 크다면 MSE&lt;/li&gt;
      &lt;li&gt;손익이 단순 오차의 크기에 비례한다면 MAE
        &lt;ul&gt;
          &lt;li&gt;케라스에서의 구현
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;keras.metrics.mean_absolute_error(x_valid, native_forecast).numpy()&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;moving-average-and-differencing&quot;&gt;Moving average and differencing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;이동 평균을 계산 : 일반적이고 간단한 예측 방법
    &lt;ul&gt;
      &lt;li&gt;노이즈를 제거하고, 원본 시계열을 대략적으로 유추하는 곡선이 도출&lt;/li&gt;
      &lt;li&gt;추세나 계절성을 예측하지는 않음 : 현재 시점에서 미래를 예측하고자 하는 기간 이후에는 단순 예측보다 결과가 저조할 수 있음&lt;/li&gt;
      &lt;li&gt;차분은 이를 피하는 방법 중 하나 : 시계열에서 추세와 계절성을 제거
        &lt;ul&gt;
          &lt;li&gt;즉, 시계열 자체를 연구하는게 아니라 T 시점의 값과 이전 기간의 값 사이의 차이를 연구&lt;/li&gt;
          &lt;li&gt;차분에 이동평균선을 예측하면 이는 차분에 대한 예측일 뿐이고, 원본 시계열에 대한 것은 아님
            &lt;ul&gt;
              &lt;li&gt;뺀 값 (이전 기간의 값) 을 다시 더해줘야 함&lt;/li&gt;
              &lt;li&gt;하지만 이전의 값을 더해줄 때 노이즈도 같이 생기게 됨. &amp;gt; 이동 평균을 이용하여 과거의 노이즈를 제거&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;trailing-versus-centered-windows&quot;&gt;Trailing versus centered windows&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Trailing Window (현재 값의 이동 평균을 산출할때)
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1000 = (t970 + t971 + ... + t999) / 30&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Centered Window (과거 값의 이동 평균을 산출할때) : 정확도가 Trailing Window 보다 높음
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t635 = (t630 + t631 + ... + t640) / 11&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;forecasting&quot;&gt;Forecasting&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;week-1-working-with-time-series&quot;&gt;Week 1: Working with time series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter notebook 자료&lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="AI" /><category term="Time Series" /><category term="Coursera" /><category term="deeplearning.ai" /><category term="Laurence Moroney" /><category term="timeseries" /><category term="시계열" /><category term="tensorflow" /><summary type="html">Introduction</summary></entry><entry><title type="html">Sequences, Time Series and Prediction - 00. 강좌소개</title><link href="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_00_About-this-course/" rel="alternate" type="text/html" title="Sequences, Time Series and Prediction - 00. 강좌소개" /><published>2022-10-17T14:00:00+09:00</published><updated>2022-10-17T14:00:00+09:00</updated><id>https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_00_About%20this%20course</id><content type="html" xml:base="https://bluesplatter.com/ai/time%20series/Sequences_TimeSeries_and_Prediction_00_About-this-course/">&lt;h1 id=&quot;강좌에-대한-설명&quot;&gt;강좌에 대한 설명&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/coursera_SequencesTimeSeriesandPrediction.png&quot; alt=&quot;강좌에 대한 설명&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;시계열 분석 학습을 위한 강좌&lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="AI" /><category term="Time Series" /><category term="Coursera" /><category term="deeplearning.ai" /><category term="Laurence Moroney" /><category term="timeseries" /><category term="시계열" /><category term="tensorflow" /><summary type="html">강좌에 대한 설명</summary></entry><entry><title type="html">Jenkins Pipeline - Declarative and IaC approaches for DevOps</title><link href="https://bluesplatter.com/jenkins/JenkinsPipeline_Declarative_and_IaC_approaches_for_DevOps/" rel="alternate" type="text/html" title="Jenkins Pipeline - Declarative and IaC approaches for DevOps" /><published>2022-09-30T14:00:00+09:00</published><updated>2022-09-30T14:00:00+09:00</updated><id>https://bluesplatter.com/jenkins/JenkinsPipeline_Declarative_and_IaC_approaches_for_DevOps</id><content type="html" xml:base="https://bluesplatter.com/jenkins/JenkinsPipeline_Declarative_and_IaC_approaches_for_DevOps/">&lt;h1 id=&quot;후기&quot;&gt;후기&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/coursera_JenkinsPipeline-DeclarativeandIaCapproachesforDevOps_course_info.png&quot; alt=&quot;강좌에 대한 설명&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;해당 강좌는 영상플레이 시간 2시간 (하지만 영어 강좌여서 3시간 이상) 소요 되는 강좌입니다.&lt;/li&gt;
  &lt;li&gt;장점은 부담되는 양의 자료 (책, 강의 등) 를 보기 전에 짧은 시간 훑어보기에 좋은 강의라는 점입니다.&lt;/li&gt;
  &lt;li&gt;대부분 Declarative Script 로 Jenkinsfile 을 작성하여 활용할 것으로 생각하는 바, 기초에 좋은 강의일듯 싶습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;강좌&quot;&gt;강좌&lt;/h1&gt;

&lt;h2 id=&quot;파이프라인이란-무엇인가&quot;&gt;파이프라인이란 무엇인가?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;정의와 기능
    &lt;ul&gt;
      &lt;li&gt;SCM(Source Code Management) 의 Continuous Delivery 절차를 위한 플러그인 집합&lt;/li&gt;
      &lt;li&gt;제품 개발 라이프사이클 (Submitting Code -&amp;gt; Testing -&amp;gt; Staging -&amp;gt; Deployment …) 에 연관&lt;/li&gt;
      &lt;li&gt;각 단계의 성공 / 실패 여부 제공&lt;/li&gt;
      &lt;li&gt;다양한 타 환경에서의 운영 지원&lt;/li&gt;
      &lt;li&gt;저장소 단계에서 실 환경 배포까지의 자동화&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;파이프라인 작성법
    &lt;ul&gt;
      &lt;li&gt;Pipeline script 를 Jenkins UI 에서 작성&lt;/li&gt;
      &lt;li&gt;Jenkins file 을 통한 작성&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;파이프라인 언어
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;declarative&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;scripted&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;jenkinsfile 의 장점
    &lt;ul&gt;
      &lt;li&gt;IaC (Infrastructure as Code)
        &lt;ul&gt;
          &lt;li&gt;application code 와 마찬가지로 취급되어 저장소에 committed 됨&lt;/li&gt;
          &lt;li&gt;저장소의 이점을 누리며, 동시에 어떤 구조로 되어있는지 구성원들이 시각적으로 확인할 수 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;파이프라인-스크립트의-형태와-전역변수&quot;&gt;파이프라인 스크립트의 형태와 전역변수&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;젠킨스 서버 구동
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java -jar jenkins.war httpPort=8080&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;브라우저에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;localhost:8080&lt;/code&gt; 으로 접속&lt;/li&gt;
      &lt;li&gt;기본 계정 로그인 : admin / admin&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;new items
    &lt;ul&gt;
      &lt;li&gt;네이밍&lt;/li&gt;
      &lt;li&gt;Pipeline 생성&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Pipeline 섹션으로 이동&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Jenkinsfile (Declarative Pipeline)
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  pipeline {
      agent any // Execute this Pipeline or any of its stages, on any available agent.
      stages {
          // stage : conceptually distinct subset or tasks performed throughout the entire pipeline
          stage(&apos;Build&apos;) { // Defines the &quot;Build&quot; stage. (Keyword is flexible)
              // Steps represents a single task.
              // It tells Jenkins what to do at a particular point in time of a particular step in the process.
              steps {
                  //  Perform some steps related to the &quot;Build&quot; stage.
              }
          }
          stage(&apos;Test&apos;) { // Defines the &quot;Test&quot; stage.
              steps {
                  // Perform some steps related to the &apos;&quot;Test&quot; stage.
              }
          }
          stage(&apos;Deploy&apos;) { Defines the &quot;Deploy&quot; stage. 
              steps {
                  // Perform some steps related to the &quot;Deploy&quot; stage.
              }
          }
      }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Environment Variables (Global Variables)
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:8080/pipeline-syntax/globals#env&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;첫-파이프라인-스크립트-작성과-환경변수-삽입&quot;&gt;첫 파이프라인 스크립트 작성과 환경변수 삽입&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;pipeline 섹션에 코드 작성&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      pipeline {
          agent any
          stages {
              stage(&apos;stage 1&apos;){
                  steps {
                      echo &quot;hello world&quot;
                      echo BUILD_ID // Global Variable
                  }
              }
          }
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;Build Now&lt;/li&gt;
      &lt;li&gt;Console Output 확인&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;environment 변수 삽입&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;environment 변수는 최상단에 위치할 수도, stage 안에 존재할 수도 있음&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      pipeline {
          agent any
          environment {
              mainenv = &apos;dev&apos;
          }
          stages {
              stage(&apos;stage 1&apos;){
                  steps {
                      echo &quot;hello world&quot;
                      echo BUILD_ID
                      echo &quot;&quot;&quot;mainenv = ${mainenv}&quot;&quot;&quot; // enject template, literals, variables
                  }
              }
          }
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      pipeline {
          agent any
          environment {
              mainenv = &apos;dev&apos;
          }
          stages {
              stage(&apos;stage 1&apos;){
                  environment{
                      subenv = &quot;prod&quot;
                  }
                  steps {
                      echo &quot;&quot;&quot;inside stage 1: mainenv = ${mainenv}&quot;&quot;&quot; // enject template, literals, variables
                      echo &quot;&quot;&quot;inside stage 1: subenv = ${subenv}&quot;&quot;&quot;
                  }
              }
              stage(&apos;stage 2&apos;){
                  steps {
                      echo &quot;&quot;&quot;inside stage 2: mainenv = ${mainenv}&quot;&quot;&quot;
                      echo &quot;&quot;&quot;inside stage 2: subenv = ${subenv}&quot;&quot;&quot; // causing error, because of scope.
                  }
              }
          }
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;실제-github-저장소를-사용한-파이프라인-스크립트-작성과-build-steps&quot;&gt;실제 Github 저장소를 사용한 파이프라인 스크립트 작성과 build steps&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;대시보드에서 new item 선택
    &lt;ul&gt;
      &lt;li&gt;Pipeline 생성
        &lt;ul&gt;
          &lt;li&gt;우측 드롭다운 메뉴에서 샘플 코드를 불러올 수 있음&lt;/li&gt;
          &lt;li&gt;Pipeline Syntax 에서 Snippet Generator 활용하기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Most common MVN build phases&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th style=&quot;text-align: left&quot;&gt;Build Phase&lt;/th&gt;
          &lt;th style=&quot;text-align: left&quot;&gt;Description&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;validate&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;Validates that the project is correct and all necessary information is available. This also makes sure the dependencies are downloaded.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;compile&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;Compiles the source code of the project.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;test&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;Runs the tests against the compiled source code using a suitable unit testing framework. These tests should not require the code be packaged or deployed.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;package&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;Packs the compiled code in its distributable format. such as a JAR.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;install&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;Install the package into the local repository, for use as a dependency in other projects locally.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;deploy&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;Copies the final package to the remote repository for sharing with other developers and projects.&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;작성한 소스코드&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      pipeline {
      	agent any
      	stages {
          	stage(&apos;Setup&apos;){
              	steps {
                   	// this will delete folder whatever the OS platform is.
                  	dir(&apos;jenkins-spring&apos;){
                      	deleteDir()               
                  	}
              	}
          	}
          	stage(&apos;Build&apos;){
              	steps {
                  	// sh : for Linux
                  	// for Windows (copy github source)
                  	bat &apos;git clone https://github.com/rudihinds/jenkins-spring.git&apos;
                  	bat &apos;mvn clean -f jenkins-spring&apos;
              	}
          	}
          	stage(&apos;Test&apos;){
              	steps {
                  	bat &apos;mvn clean test -f jenkins-spring&apos;
              	}
          	}
          	stage(&apos;Deploy&apos;){
              	steps {
                  	bat &apos;mvn clean package -f jenkins-spring&apos;
              	}
          	}
      	}
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;jenkinsfile-을-이용하여-scm-에-파이프라인-연결&quot;&gt;Jenkinsfile 을 이용하여 SCM 에 파이프라인 연결&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;SCM 을 통해 어떻게 파이프라인을 가져올 수 있는지?&lt;/li&gt;
  &lt;li&gt;복잡한 Microarchitecture 구조가 아니라면 보편적으로 Jenkinsfile 은 프로젝트의 root 디렉토리에 있음&lt;/li&gt;
  &lt;li&gt;Github 에 있는 Jenkinsfile 에 작성된 declarative script 와 지금까지 작성한 스크립트의 차이점
    &lt;ul&gt;
      &lt;li&gt;clone 스테이지가 없음 : Github의 Jenkinsfile을 사용한다는 것은 이미 Jenkins 에게 SCM 에서 소스코드를 가져오라고 지시한 것임&lt;/li&gt;
      &lt;li&gt;setup 스테이지가 없음 : 해당 프로세스는 이미 통합되어 있음 (Jenkins가 핸들링)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;실습
    &lt;ul&gt;
      &lt;li&gt;새 파이프라인을 만들고, 파이프라인의 정의를 Pipeline script from SCM 으로 설정
        &lt;ul&gt;
          &lt;li&gt;SCM 종류 Git으로 설정&lt;/li&gt;
          &lt;li&gt;Repository URL 설정&lt;/li&gt;
          &lt;li&gt;브랜치 설정&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Build Now
        &lt;ul&gt;
          &lt;li&gt;Declarative: Checkout SCM 스테이지가 자동생성된 것을 확인할 수 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="Jenkins" /><category term="Coursera" /><category term="Rudi Hinds" /><category term="Jenkins" /><category term="Declarative and IaC approaches for DevOps" /><category term="젠킨스" /><category term="CI/CD" /><summary type="html">후기</summary></entry><entry><title type="html">Jenkins - Automating your delivery pipeline</title><link href="https://bluesplatter.com/jenkins/Jenkins_Automating_your_dilivery_pipeline/" rel="alternate" type="text/html" title="Jenkins - Automating your delivery pipeline" /><published>2022-09-29T16:00:00+09:00</published><updated>2022-09-29T16:00:00+09:00</updated><id>https://bluesplatter.com/jenkins/Jenkins_Automating_your_dilivery_pipeline</id><content type="html" xml:base="https://bluesplatter.com/jenkins/Jenkins_Automating_your_dilivery_pipeline/">&lt;h1 id=&quot;후기&quot;&gt;후기&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/coursera_Automatingyourdeliverypipeline_course_info.png&quot; alt=&quot;강좌에 대한 설명&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;해당 강좌는 영상플레이 시간 1시간 (하지만 영어 강좌여서 2시간 이상) 소요 되는 강좌입니다.&lt;/li&gt;
  &lt;li&gt;개인적으로 추천하고 싶지는 않은데, 내용을 떠나 구축된 Cloud 환경의 젠킨스가 구 버전이어서 플러그인과 호환이 되질 않습니다.&lt;/li&gt;
  &lt;li&gt;실습의 절반정도는 영상을 보는 것으로만 하였습니다.&lt;/li&gt;
  &lt;li&gt;장점은 부담되는 양의 자료 (책, 강의 등) 를 보기 전에 짧은 시간 훑어보기에 좋은 강의라는 점입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;jenkins-란&quot;&gt;Jenkins 란?&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;DevOps 환경에서 Continuous integration and Delivery 를 가능하게 하는 툴&lt;/li&gt;
  &lt;li&gt;Continuous Delivery
    &lt;ul&gt;
      &lt;li&gt;개발자가 개발한 새 소스코드를 즉시 소스코드 저장소에 반영&lt;/li&gt;
      &lt;li&gt;빌딩, 테스팅, 패키징이 등이 일어나 배포 가능 버전이 생성됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이점
    &lt;ul&gt;
      &lt;li&gt;배포속도가 빨라짐&lt;/li&gt;
      &lt;li&gt;피드백을 빨리 받을 수 있음&lt;/li&gt;
      &lt;li&gt;초기 단게에서 결함을 발견할 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;실습&quot;&gt;실습&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;젠킨스 서버에서 사용하기 위한 Maven 설정
    &lt;ul&gt;
      &lt;li&gt;DashBoard 에서 Global Tool Configuration 설정&lt;/li&gt;
      &lt;li&gt;하단의 Maven 설치 (네이밍 포함)&lt;/li&gt;
      &lt;li&gt;Maven : 자바용 프로젝트 빌드, 관리에 사용되는 도구&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;라이브러리의 추가, 라이브러리 버전 동기화의 어려움을 해소&lt;/li&gt;
      &lt;li&gt;프로젝트 생성, 테스트 빌드, 배포 등의 작업을 위함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Spring pet clinic 어플리케이션의 첫번째 Job 생성
    &lt;ul&gt;
      &lt;li&gt;Spring pet clinic 의 깃헙 소스코드 fork 하기&lt;/li&gt;
      &lt;li&gt;Jenkins 의 파이프라인 첫 단계는 compile stage 혹은 build stage 가 될 것&lt;/li&gt;
      &lt;li&gt;New Item&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;Freestyle project : 어떠한 제약, 제한조건 없는 프로젝트
        &lt;ul&gt;
          &lt;li&gt;네이밍하기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;섹션들
        &lt;ul&gt;
          &lt;li&gt;General&lt;/li&gt;
          &lt;li&gt;Source Code Management&lt;/li&gt;
          &lt;li&gt;Build Triggers&lt;/li&gt;
          &lt;li&gt;Build Environment&lt;/li&gt;
          &lt;li&gt;Build&lt;/li&gt;
          &lt;li&gt;Post-build Actions&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Source Code Management 설정
        &lt;ul&gt;
          &lt;li&gt;Git URL 값 입력&lt;/li&gt;
          &lt;li&gt;Branch 입력 (소스코드가 위치하는 경로)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Build 설정
        &lt;ul&gt;
          &lt;li&gt;Add build step -&amp;gt; Invoke top-level Maven targets : Maven 을 통한 build task 수행&lt;/li&gt;
          &lt;li&gt;Maven 버전 설정 : Global Tool Configuration 에서 네이밍한 Maven 선택&lt;/li&gt;
          &lt;li&gt;Goals 설정 : compile 입력&lt;/li&gt;
          &lt;li&gt;Save
            &lt;ul&gt;
              &lt;li&gt;Build Now&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;#1 빌드 수행&lt;/li&gt;
      &lt;li&gt;버튼 색에 따른 상태
        &lt;ul&gt;
          &lt;li&gt;Blue : 성공(완료)&lt;/li&gt;
          &lt;li&gt;Blinking : 현재 실행중&lt;/li&gt;
          &lt;li&gt;Rend : 실패&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;버튼 옆 arrow -&amp;gt; Console Output 으로 결과 확인&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Delivery Pipeline 생성하기 (Build, Test Stage 생성하기)
    &lt;ul&gt;
      &lt;li&gt;Jenkins -&amp;gt; New Item&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;Freestyle project
        &lt;ul&gt;
          &lt;li&gt;네이밍하기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Source Code Management 설정
        &lt;ul&gt;
          &lt;li&gt;Git URL 값 입력&lt;/li&gt;
          &lt;li&gt;Branch 입력 (소스코드가 위치하는 경로)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Build 설정
        &lt;ul&gt;
          &lt;li&gt;Add build step -&amp;gt; Invoke top-level Maven targets : Maven 을 통한 build task 수행&lt;/li&gt;
          &lt;li&gt;Maven 버전 설정 : Global Tool Configuration 에서 네이밍한 Maven 선택&lt;/li&gt;
          &lt;li&gt;Goals 설정 : test 입력&lt;/li&gt;
          &lt;li&gt;Save
            &lt;ul&gt;
              &lt;li&gt;Build Now&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;#1 빌드 수행&lt;/li&gt;
      &lt;li&gt;Console Output 에서 테스트 케이스에 대한 성공/실패여부를 볼 수 있음
    - Test Job 의 Configure (Build 수행 후 Test 를 진행하고 싶다)&lt;/li&gt;
      &lt;li&gt;Build Triggers : 어떻게 특정 Job 을 Trigger 할지 설정
        &lt;ul&gt;
          &lt;li&gt;Build after other projects are built
            &lt;ul&gt;
              &lt;li&gt;Projects to watch : Build Job 입력&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Save
            &lt;ul&gt;
              &lt;li&gt;Pipeline 전체를 살펴보기 위해 Plugin 설치하기&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Jenkins -&amp;gt; Manage Jenkins -&amp;gt; Manage Plugins
        &lt;ul&gt;
          &lt;li&gt;Available tab -&amp;gt; search Build pipeline -&amp;gt; install&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Jenkins Dashboard 의 작은 + 버튼 클릭 -&amp;gt; Build Pipeline View
        &lt;ul&gt;
          &lt;li&gt;네이밍&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Pipeline Flow -&amp;gt; Upstream / downstream config
        &lt;ul&gt;
          &lt;li&gt;Initial Job (첫 시작 Job) 설정&lt;/li&gt;
          &lt;li&gt;초록색 Job : 이미 실행된 Job&lt;/li&gt;
          &lt;li&gt;파란색 Job : 아직 실행되지 않은 Job&lt;/li&gt;
          &lt;li&gt;노란색 Job : 실행중인 Job&lt;/li&gt;
          &lt;li&gt;빨간색 Job : Job 실패&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Run&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Codify Pipeline
    &lt;ul&gt;
      &lt;li&gt;Build pipeline 의 코드화 필요성&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;위 활동에서의 Configuration Setup 을 직접 수행할 경우 신뢰성이 떨어짐&lt;/li&gt;
      &lt;li&gt;Jenkins 는 Groovy Script 를 사용함
    - Pipeline Maven integration plugin 설치&lt;/li&gt;
      &lt;li&gt;메이븐과 젠킨스의 통합을 쉽게 해줌&lt;/li&gt;
      &lt;li&gt;scripted pipeline 에서 사용할 많은 Wrapper methods 를 제공
    - New item&lt;/li&gt;
      &lt;li&gt;Pipeline
        &lt;ul&gt;
          &lt;li&gt;Pipeline Tab&lt;/li&gt;
        &lt;/ul&gt;

        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  node{
      stage(&apos;Checkout&apos;){
          git branch: &apos;main&apos;, url:&apos;https://github.com/HY03/SpringPetClinic.git&apos;
      }
      stage(&apos;Build&apos;){
          withMaven(maven: &apos;M3&apos;){
              sh &apos;mvn compile&apos;
          }
      }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  - node : where you run your job
      + master : where jenkins installed
      + slave : for the distributed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;declarative pipeline
    &lt;ul&gt;
      &lt;li&gt;필요성&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;Jenkins 와 엮여있는 Groovy Script 의 어려움
    - New item&lt;/li&gt;
      &lt;li&gt;Pipeline
        &lt;ul&gt;
          &lt;li&gt;Pipeline Tab&lt;/li&gt;
        &lt;/ul&gt;

        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  pipeline{
      agent{label &apos;master&apos;}
      tools{maven &apos;M3&apos;}
      stages{
          stage(&apos;Checkout&apos;){
              steps{
                  git branch: &apos;main&apos;, url:&apos;https://github.com/HY03/SpringPetClinic.git&apos;&apos;
              }
          }
          stage(&apos;Build&apos;){
              steps{
                  sh &apos;mvn compile&apos;   
              }
          }
          stage(&apos;Test&apos;){
              steps{
                  sh &apos;mvn test&apos;
              }
          }
          stage(&apos;Package&apos;){
              steps{
                  sh &apos;mvn package&apos;
              }
          }
          stage(&apos;Deploy&apos;){
              steps{
                  sh &apos;java -jar /var/lib/jenkins/workspace/PetClinicDeclarativePipeline/target/*.jar&apos;
              }
          }
      }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  - `sh &apos;mvn [goal]&apos;` : 실행할 mvn goal 설정
  - 메이븐은 여러 플러그인으로 구성되어 있으며, 각각의 플러그인은 하나 이상의 goal(명령, 작업)을 포함하고 있다. 
  - Goal은 Maven의 실행 단위이다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Declarative Pipeline 을 Jenkins File 로 저장시켜 저장소에 저장하기
    &lt;ul&gt;
      &lt;li&gt;소스코드 저장소에 Jenkins Pipeline 스크립트를 복사&lt;/li&gt;
      &lt;li&gt;Github 에서 파일 생성 : Jenkinsfile (파일명은 고정)&lt;/li&gt;
      &lt;li&gt;Job 의 Pipeline 설정에서 Pipeline script 대신 Pipeline script from SCM 선택&lt;/li&gt;
      &lt;li&gt;Git 경로 및 Branch 설정&lt;/li&gt;
      &lt;li&gt;Script Path : jenkinsfile 위치 설정&lt;/li&gt;
      &lt;li&gt;Lightweight Checkout 설정 : jenkinsfile 먼저 checkout 한 뒤, jenkinsfile 의 모든 스테이지를 수행&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="Jenkins" /><category term="Coursera" /><category term="Anju M Dominic" /><category term="Jenkins" /><category term="Automating your delivery pipeline" /><category term="젠킨스" /><category term="CI/CD" /><summary type="html">후기</summary></entry><entry><title type="html">A Life of Happiness and Fulfillment - 08. 요약</title><link href="https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-08_Summary/" rel="alternate" type="text/html" title="A Life of Happiness and Fulfillment - 08. 요약" /><published>2022-09-27T18:00:00+09:00</published><updated>2022-09-27T18:00:00+09:00</updated><id>https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-08_Summary</id><content type="html" xml:base="https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-08_Summary/">&lt;h1 id=&quot;요약&quot;&gt;요약&lt;/h1&gt;

&lt;h2 id=&quot;mba-접근법&quot;&gt;MBA 접근법&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;행복하고 충만한 삶의 결정 요인이 무엇일까?
    &lt;ul&gt;
      &lt;li&gt;기본적인 욕구 충족 (옷, 음식, 거주지)&lt;/li&gt;
      &lt;li&gt;어떤 것을 잘한다는 느낌 (숙달의 욕구)
        &lt;ul&gt;
          &lt;li&gt;우월함의 욕구 vs 몰입&lt;/li&gt;
          &lt;li&gt;자신의 행복에 자기자신이 책임 지는 것&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;최소한 한 사람과의 감정, 유대감 (소속감의 욕구)
        &lt;ul&gt;
          &lt;li&gt;사랑받고자 하는 욕구 vs 사랑받고 베풀고자 하는 욕구&lt;/li&gt;
          &lt;li&gt;안정적 애착&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;자유에 대한 욕구 (자율성)
        &lt;ul&gt;
          &lt;li&gt;외부에 대한 통제 vs 내부에 대한 통제&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;숙달 (&lt;strong&gt;M&lt;/strong&gt;astery), 유대감 (&lt;strong&gt;B&lt;/strong&gt;elongingness), 자율성 (&lt;strong&gt;A&lt;/strong&gt;utonomy)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;두-가지-경로&quot;&gt;두 가지 경로&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;결핍의 경로 (Scarcity approach)&lt;/li&gt;
  &lt;li&gt;풍족함의 경로 (Abundance approach)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mba-에-적용&quot;&gt;MBA 에 적용&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;숙달 (Mastery)
    &lt;ul&gt;
      &lt;li&gt;결핍의 경로 : 우월을 좇는 것 (Pursuing superiority)&lt;/li&gt;
      &lt;li&gt;풍족함의 경로 : 몰입을 추구하는 것 (Pursuing flow)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;유대감 (Belongingness)
    &lt;ul&gt;
      &lt;li&gt;결핍의 경로 : 사랑받고자 하는 욕구 (Need to be loved)&lt;/li&gt;
      &lt;li&gt;풍족함의 경로 : 사랑하고 베풀고자 하는 욕구 (Need to love (and give))&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;자율성 (Autonomy)
    &lt;ul&gt;
      &lt;li&gt;결핍의 경로 : 외적 (타인, 결과) 조절에 관한 욕구 (Need for external control)&lt;/li&gt;
      &lt;li&gt;풍족함의 경로 :  내적 조절에 관한 욕구 (Need for internal control)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;마음챙김-mindfulness&quot;&gt;마음챙김 (Mindfulness)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;의자 (행복) 의 다른 세 다리 (숙달, 유대감, 자율성) 을 지탱해주는 중심 기둥&lt;/li&gt;
  &lt;li&gt;숙달, 유대감, 자율성의 증진에 도움이 됨&lt;/li&gt;
  &lt;li&gt;숙달
    &lt;ul&gt;
      &lt;li&gt;마음챙김은 창의성과 통찰력을 길러줌&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;유대감
    &lt;ul&gt;
      &lt;li&gt;마음챙김은 동정심을 길러줌&lt;/li&gt;
      &lt;li&gt;뇌의 영역 활성화 (미주 긴장도, 섬피질)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;자율성
    &lt;ul&gt;
      &lt;li&gt;마음챙김은 내적 통제를 더 잘하게 도와줌&lt;/li&gt;
      &lt;li&gt;특정상황에서 더 잘 반응 (반응 유연성)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;그-외의-항목&quot;&gt;그 외의 항목&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;신뢰, 타인을 믿는 것, 삶을 믿는 것&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;행복-유지에-대한-전략&quot;&gt;행복 유지에 대한 전략&lt;/h1&gt;

&lt;h2 id=&quot;행복-유지의-어려움&quot;&gt;행복 유지의 어려움&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;오래된 습관은 잘 고쳐지지 않기 때문
    &lt;ul&gt;
      &lt;li&gt;행복 수치를 낮추는 습관이 몇 년 사이에 몸에 밴 것
        &lt;ul&gt;
          &lt;li&gt;전형적인 회사원 : 우월함을 좇는 욕구를 높이거나 결핍을 더 많이 느끼게 하는 메시지를 많이 받음&lt;/li&gt;
          &lt;li&gt;매일 쏟아지는 부정적인 뉴스 (불신)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;행복에 대한 7가지 죄악과 이를 방지할 방법을 숙지
    &lt;ul&gt;
      &lt;li&gt;행복과 관련한 잘못을 줄이는 방법, 행복 습관을 강화하는 방법을 알아야 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;7가지-전략&quot;&gt;7가지 전략&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;일일 질문 과정 (동료 코치라는 것을 통해 &lt;strong&gt;매일 질문을 받는 것&lt;/strong&gt;)&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 	어제 얼마나 많이 스스로가 옳다고 증명하려고 했나요? 증명할 필요가 없었는데요 말이죠.
 	조금 과하다 싶을 정도로 옳은 행동을 하려고 하시지는 않았나요?
 	다른사람에게 얼마나 많이 화내고 불평했나요?
 	다른사람에게 좋은 말을 해줬나요?
 &amp;gt; 	이를 계속 기억하기 위함
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;꿈에 관한 내용
        &lt;ul&gt;
          &lt;li&gt;지금 바쁘기 때문에 할 수 없다.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;2개월 ~ 3개월 후 상황이 바뀔 것이고, 재충전 후에 모든게 다시 좋아질 것이다.&lt;/strong&gt; (X)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;아주 바쁘고, 부담감도 많고, 피곤하고, 체력이 고갈되어 있기 때문에 이를 모두 머리속으로 기억하는 것은 아주 어려운 일&lt;/li&gt;
      &lt;li&gt;행복을 우선으로 하는 것을 나중으로 미루기 때문&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;매일매일, 오늘, 행복하기 위해 노력하는 것&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;긍정적인 언어로 목표를 설정&lt;/strong&gt;하기
    &lt;ul&gt;
      &lt;li&gt;자신의 목표를 부정적으로 바라보는 대신 이를 좀 더 긍정적으로 봐야 함
        &lt;ul&gt;
          &lt;li&gt;금연, 소식, 이메일 체크 줄이기 -&amp;gt; 건강해지기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;그래야 이를 전부 멈추는 대신 대체할 만한 행동을 찾게 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;자신의 환경을 바꾸기&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;올바른 행동은 하기 쉽도록 만들고, 올바르지 않은 행동은 하기 어렵게 만드는 것&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;행복과 풍요로움을 추구하는 &lt;strong&gt;다른 사람들과 어울리기&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;인간은 사회적 동물이고, 혼자서는 그 무엇도 할 수 없다.&lt;/li&gt;
      &lt;li&gt;목표는 전염됨. 특정한 것을 하는 사람들과 어울리게 되면, 그 사람이 하는 것을 하고 싶게 됨&lt;/li&gt;
      &lt;li&gt;내가 하고자 하는 행동을 하는 사람들과 어울리게 되면, 자연스럽게 그들과 어울리게 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;누군가의 &lt;strong&gt;멘토가 되어주기&lt;/strong&gt; (멘티를 신중히 선택해야 함)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;내가 얼마나 진행하였는지 알 수 있게 되고 다시 동기부여가 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;개방적인 태도를 가지기&lt;/strong&gt; (이 외의 다양한 방법들) - 자신의 정체성이 정해져 있다고 생각하지 말기
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;진화하려면 다른 것을 받아들여야 한다. (친숙해지기 이전 시점까지는 불편할 것임)&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;지금 하는 특정 행동으로 얻는 행복이 같은 것을 계속 지속함으로서 미래에 같은 행복을 얻는다고 생각하기 어려움&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;그저 새롭다는 이유만으로 하고싶지 않은 것인지 생각해보기&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="A Life of Happiness and Fulfillment (행복하고 보람찬 삶)" /><category term="Coursera" /><category term="Indian School of Business" /><category term="Dr. Rajagopal Raghunathan" /><category term="A Life of Happiness and Fulfillment" /><category term="긍정심리학" /><category term="행복" /><summary type="html">요약</summary></entry><entry><title type="html">A Life of Happiness and Fulfillment - 07. 내부의 근원을 무시</title><link href="https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-07_Ignoring-The-Source-Within/" rel="alternate" type="text/html" title="A Life of Happiness and Fulfillment - 07. 내부의 근원을 무시" /><published>2022-09-24T18:00:00+09:00</published><updated>2022-09-24T18:00:00+09:00</updated><id>https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-07_Ignoring%20The%20Source%20Within</id><content type="html" xml:base="https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-07_Ignoring-The-Source-Within/">&lt;h1 id=&quot;내부의-근원을-무시하는-것&quot;&gt;내부의 근원을 무시하는 것&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;여러 가지 측면에서 가장 중요한 잘못&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;마음챙김-mindfulness-이란&quot;&gt;마음챙김 (Mindfulness) 이란?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;현재 일어나는 일 이외의 것을 생각하지 않는 것&lt;/li&gt;
  &lt;li&gt;상사가 소리를 치거나, 사고를 당하는 상황에서도… 정신이 분산되지 않는 것&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;아리스토텔레스 : 행복은 최고의 선 이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;좋은 집, 좋은 차, 좋은 직업 &amp;gt; 본질적으로 가치가 있는 것이 아님 (행복을 얻는 수단)&lt;/li&gt;
  &lt;li&gt;행복의 역설 : 많이 개선된 객관적 환경에서 살더라도 실제로 더 행복해지지 않음&lt;/li&gt;
  &lt;li&gt;행복에 관련한 연구 : 소득, 교육, 성별, 결혼 … &amp;gt; 행복에 강력히 영향을 미치는 요소는 없었음&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;행복에 강한 영향을 주는 요소&lt;/strong&gt; : &lt;strong&gt;매 순간 경험하는 것들&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;무엇을 하고 있는지&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;누구와 함꼐 있는지&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;어떤 생각을 하고있는지&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;공상 (Mind-wandering) : 현재의 순간이 아닌 다른 것에 집중하는 것
    &lt;ul&gt;
      &lt;li&gt;현재에 몰입해야 한다. (사회적 통념)&lt;/li&gt;
      &lt;li&gt;현재의 순간보다 더 좋은 상황을 공상하는 것 &amp;gt; 행복에 영향&lt;/li&gt;
      &lt;li&gt;그러나 출퇴근길 교통체증 속에서 공상을 하는 것 보다 교통체증 속에서 집중하는 편이 더 행복하다는 연구결과
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;사람들은 주로 괴로운 것에 대해 공상한다. (걱정, 불안, 후회)&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;마음챙김 상태에 있으면 상대적으로 더 행복하다.&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;아주 기쁜 상태이더라도 현재에 집중하는 것은 어렵다.&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;공상을 하지 않을 때 행복하거나 덜 불행한 경향이 있다.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;마음챙김이 항상 집중하라는 뜻은 아니다.&lt;/li&gt;
  &lt;li&gt;안좋은 것을 경험하고 있을 때도 행복의 레벨을 높일 수 있음.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;우리 안에 마음 챙김이란 행복의 근원이 있음.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;마음챙김-mindfulness-능력을-기르기&quot;&gt;마음챙김 (Mindfulness) 능력을 기르기&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;몰입 상태에서 마음챙김을 하기 쉽다. (주의가 분산되지 않는다.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;공상을-컨트롤하기&quot;&gt;공상을 컨트롤하기&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;긍정적인 상황에서는 쉽다.&lt;/li&gt;
  &lt;li&gt;부정적인 상황 (스트레스를 받는 상황) 에서는 어렵다.
    &lt;ul&gt;
      &lt;li&gt;부정적인 상황이 되면 “반추” 를 하게 됨.
        &lt;ul&gt;
          &lt;li&gt;상사가 나에게 큰소리를 쳤을 때, 공상을 통해 내년에 내가 해고당할지도 모른다는 생각을 하게 됨.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;다른 생각을 하지 않고 짜증나는 것에 대해 온전히 느끼기
        &lt;ul&gt;
          &lt;li&gt;감정이 더 심화될 수도 약해질 수도 있음.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;마음챙김은 어떤 면에서 보면, 감정을 조절하는 것의 반대라 할 수 있음.&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;감정조절전략&lt;/strong&gt;
            &lt;ul&gt;
              &lt;li&gt;&lt;strong&gt;상사가 큰소리 치고 있는 상황에서 상사에게 칭찬을 들었던 다른 기억 떠올리기&lt;/strong&gt;&lt;/li&gt;
              &lt;li&gt;&lt;strong&gt;달리기를 하거나 다른 화제의 이야기를 나누는 등 다른 생각으로 대체&lt;/strong&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;마음 챙김의 상태에 있는 것이 감정 조절 전략보다 더 강력하게 감정을 조절할 수 있음&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;마음 챙김 상태에서 무언가를 통제하려고 하면 안됨.
            &lt;ul&gt;
              &lt;li&gt;생각과 감정을 조절하는 것과 정 반대의 것&lt;/li&gt;
              &lt;li&gt;&lt;strong&gt;일을 판단하지 않거나, 생각하지 않은 채로 관찰하고자 하는 것&lt;/strong&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;예시 : TV를 보다가 탁아소에서 아이를 데려올 시간이 지났다는 것을 생각하게 됨
        &lt;ul&gt;
          &lt;li&gt;“내가 좀 더 정신을 차려야겠다” &amp;gt; “늘 실수하고 뭘 제대로 제 시간에 해내지를 못하네” &amp;gt; 죄책감&lt;/li&gt;
          &lt;li&gt;TV를 끄고 차를 타고 중간에 아이가 좋아하는 과자를 사서 감&lt;/li&gt;
          &lt;li&gt;생각 하나만으로 생각, 감정, 행동경향, 목표가 형성&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;gates--gate-라고-부르는-하나의-망에-빠지는-것&quot;&gt;GATEs : GATE 라고 부르는 하나의 망에 빠지는 것&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;G&lt;/strong&gt;oals : 목표&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;A&lt;/strong&gt;ctions or Action-tendencies : 행동 혹은 행동 경향&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T&lt;/strong&gt;houghts : 생각&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;E&lt;/strong&gt;motions : 감정&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;부정적 감정 -&amp;gt; 부정적 생각 -&amp;gt; 행동(감정을 촉발하는) -&amp;gt; 새로운 생각 -&amp;gt; 새로운 행동 -&amp;gt; … (일반적)&lt;/li&gt;
  &lt;li&gt;상사가 소리를 쳤을 때 건강한 방식으로 반응한다면 이것은 그다지 나쁘지 않을 수도 있음. 하지만 어려움.
    &lt;ul&gt;
      &lt;li&gt;우월함을 좇고자 하는 마음&lt;/li&gt;
      &lt;li&gt;과하게 통제하려는 마음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;순환고리를 깨는 방법 중 하나는 매우 행복하기 위한 습관을 만드는 것
    &lt;ul&gt;
      &lt;li&gt;우월함을 좆고자 하는 마음 -&amp;gt; 몰입&lt;/li&gt;
      &lt;li&gt;과하게 통제하려는 마음 -&amp;gt; 내적 통제&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GATE 라는 망에서 벗어나기&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;벽에-붙어있는-파리가-되기&quot;&gt;벽에 붙어있는 파리가 되기&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;객관적인 관찰자 되기 (편견없이 있는 그대로 보기)&lt;/strong&gt; != 관심이 없는 것&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;상황을 바꿀 수 있는 힘이 없음 &amp;gt; 당시 일어나는 일을 있는 그대로 받아들일 수밖에 없음&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;머리 속에서 일어나는 일에 대해
    &lt;ul&gt;
      &lt;li&gt;벽에 붙어있는 파리가 되기&lt;/li&gt;
      &lt;li&gt;주목을 받길 원한다거나 일을 바꾸고 싶어하지 않을 것&lt;/li&gt;
      &lt;li&gt;생각을 바꿀 수 있음&lt;/li&gt;
      &lt;li&gt;아이스크림 버킷을 10분안에 먹으며, 자신이 비열한 게으름뱅이라고 생각한다고 가정
        &lt;ul&gt;
          &lt;li&gt;“그럴 수 있지, 최근 이혼을 겪어서 힘들었잖아.”&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;어떤 일이 일어나는지 단순히 지켜보기&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;GATE 망이 점점 느려지게 됨&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;자신과 현재 벌어지고 있는 일 사이에 거리를 두기 때문
            &lt;ul&gt;
              &lt;li&gt;좀 더 평화로움을 느끼며 스트레스를 덜 받게 됨&lt;/li&gt;
              &lt;li&gt;&lt;strong&gt;반응 유연성의 향상&lt;/strong&gt;
                &lt;ul&gt;
                  &lt;li&gt;&lt;strong&gt;언제, 어떤 감정이나 목표가 특정한 생각을 발생시킬 지 정할 수 있게됨&lt;/strong&gt;&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;마음챙김의 모순?
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;벽에 붙은 파리에 비유, 객관적인 관찰자 되기&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;현재 일어나고 있는 일에 완전히 몰두하기&lt;/strong&gt; (다른 일에 정신 팔리는 것이 아님)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;현재에-집중하기&quot;&gt;현재에 집중하기&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;GATE 밖으로 나오는 것이 비록 자신과 현재 머리 속에서 일어나는 일에 대해 거리를 두는 것으로 보이기는 하지만 이를 통해 실제로는 이를 단순히 생각만 하는 것이 아니라 마음 챙김을 하는 것이란 걸 알 수 있음&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;매 순간 현실에 깊게 다가가려 하는 것&lt;/strong&gt; != GATE 를 통해 과거 안좋은 기억까지 떠올리며 시간여행을 하는 것&lt;/li&gt;
  &lt;li&gt;현재 일어나는 일을 바꾸려 하는 것이 아님&lt;/li&gt;
  &lt;li&gt;벽에 붙어있는 파리가 되어 현재에 존재하는 것 -&amp;gt; GATE 도 현재로 돌아오게 됨&lt;/li&gt;
  &lt;li&gt;벽에 붙어 있는 파리가 되면 어떤 결과가 나타나는지?
    &lt;ul&gt;
      &lt;li&gt;더 차분해짐&lt;/li&gt;
      &lt;li&gt;반응 유연성의 향상&lt;/li&gt;
      &lt;li&gt;감각을 더 잘 유지할 수 있음 (GATE 가 현재로 돌아오면서)
        &lt;ul&gt;
          &lt;li&gt;머리 속에서 쓰는 시간을 줄임&lt;/li&gt;
          &lt;li&gt;마음속의 GATE 에서 쓰는 시간을 줄임&lt;/li&gt;
          &lt;li&gt;몸에 쓰는 시간을 늘림&lt;/li&gt;
          &lt;li&gt;사물을 더 선명하게 보고 들을 수 있게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;삶이 당장 흥미롭다고 생각하거나, 머리속에서 새롭고 존재하지 않는 현실을 생각할 필요도 없을 거라 생각할 수도 있음&lt;/li&gt;
      &lt;li&gt;삶은 지금 당장 부유하고 풍부하고, 심지어 신비롭고 아주 고무적일 수도 있음&lt;/li&gt;
      &lt;li&gt;특히 현재를 인식하는 아주 강렬한 경험을 한 적이 있다면, 여러분은 지금 세상을 완전히 새로운 눈으로 보고 새로운 귀로 들을 것이라 느낄 수도 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;세상을 마음의 GATE 를 통해 왜곡해서 보는 것이 아닌, 직접 보는 것&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;마음챙김의-이점&quot;&gt;마음챙김의 이점&lt;/h1&gt;

&lt;h2 id=&quot;잘-사는-것-well-being-의-강력한-요인&quot;&gt;잘 사는 것 (well-being) 의 강력한 요인&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;차분하게 만들어줌 (스트레스를 낮춰줌)&lt;/li&gt;
  &lt;li&gt;모든 상황에 좀 더 유연하고 의식적인 방법으로 대처할 수 있게 해줌&lt;/li&gt;
  &lt;li&gt;감정 지능을 더 많이 사용하여 우리 삶에 일어나는 일들에 대응하도록 도와줌&lt;/li&gt;
  &lt;li&gt;감정 지능의 상승&lt;/li&gt;
  &lt;li&gt;우리를 현재에 머물게 해줌 : 일상적인 것들은 낯설고 더 흥미롭게 볼 수 있도록 해줌&lt;/li&gt;
  &lt;li&gt;감각상 시간이 더 많은 것처럼 느껴짐&lt;/li&gt;
  &lt;li&gt;뇌의 생리적 구조를 변화시킴
    &lt;ul&gt;
      &lt;li&gt;긍정적(좌-&amp;gt;우), 부정적(우-&amp;gt;좌) 감정을 느낄 때 활성화되는 뇌의 부분이 다름.&lt;/li&gt;
      &lt;li&gt;실험을 통해 명상을 통해 활성화되는 뇌 신호의 방향 (좌-&amp;gt;우) 의 비율을 개선되는 것을 확인함&lt;/li&gt;
      &lt;li&gt;사람은 적정 체중처럼 적정한 행복의 기준점을 타고남 (늘리거나 할 수는 없음)
        &lt;ul&gt;
          &lt;li&gt;복권에 당첨되더라도 1년 후엔 정상 범위의 행복 수준으로 되돌아옴&lt;/li&gt;
          &lt;li&gt;불의의 사고를 당하더라도 1년 후엔 정상 범위의 행복 수준으로 되돌아옴&lt;/li&gt;
          &lt;li&gt;즉, 외부환경으로 행복 수치를 개선할 수 없음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;우리의 정신과 마음, 몸을 훈련시켜 내적 환경을 개선하여 행복 수치를 개선할 수 있음
        &lt;ul&gt;
          &lt;li&gt;신경가소성 : 반복적인 경험이 우리의 뇌를 형성한다.&lt;/li&gt;
          &lt;li&gt;마음챙김은 뇌에 여러 방향의 고속도로를 닦는 것과 같다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;육체에-긍정적인-효과&quot;&gt;육체에 긍정적인 효과&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;몸 속 염증 수치가 낮아짐&lt;/li&gt;
  &lt;li&gt;심장 건강의 향상 (부정맥 등), 정신 건강의 향상&lt;/li&gt;
  &lt;li&gt;텔로미어가 짧아지는 것을 막아줌
    &lt;ul&gt;
      &lt;li&gt;암의 발병을 막아줌&lt;/li&gt;
      &lt;li&gt;노화를 늦춰줌&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;정신에-긍정적인-효과&quot;&gt;정신에 긍정적인 효과&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;어떤 것에 적응하는 속도를 늦춰줌
    &lt;ul&gt;
      &lt;li&gt;행복 수치를 높이는 데 도움을 줌&lt;/li&gt;
      &lt;li&gt;어떤 것에 충분히 집중하기만 한다면 지루할 일은 없을 것
        &lt;ul&gt;
          &lt;li&gt;원래부터 지루한 것은 없으며, 관심이 부족한 것이다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;사랑하고 베푸는 것이 더 쉬워짐 (동정심을 더 많이 갖게 함)
    &lt;ul&gt;
      &lt;li&gt;도피질이라고 하는 뇌의 일부가 활성화 되어 공감능력이 향상됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;성공할-확률을-높여줌&quot;&gt;성공할 확률을 높여줌&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;특정 상황에 자신이 원하는 대응을 할 수 있도록 여유를 갖게 해줌
    &lt;ul&gt;
      &lt;li&gt;반응 유연성이 높아져 감정 지능이 향상하기 때문&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;창의성 향상
    &lt;ul&gt;
      &lt;li&gt;침착한 상태일 때 경험과 지식을 최대로 이용할 수 있음&lt;/li&gt;
      &lt;li&gt;서로 다른 경험과 지식을 연결할 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;마음챙김-수행의-장애-요인&quot;&gt;마음챙김 수행의 장애 요인&lt;/h1&gt;

&lt;h2 id=&quot;마음챙김의-동기부여에-대한-장애-요인&quot;&gt;마음챙김의 동기부여에 대한 장애 요인&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;마음챙김이 비과학적으로 느껴지는 것 (추상적)
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;마음챙김 : 현실을 바라보는 것&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;현실 : 머리속 현실, GATE의 현실, 외부의 현실 등&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;이 현실에 대해 함부로 판단하거나, 주석을 달거나, 집착하지 않는 것&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;객관적으로 흥미를 가진 채 현실을 보는 것&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;머릿 속 필터를 거치지 않은 채 현실을 그대로 보는 것&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;마음챙김이 추상적으로 느껴지는 것
        &lt;ul&gt;
          &lt;li&gt;자신 스스로가 현실을 정확하게 보고 모든 것을 있는 그대로 본다고 확신 중인 경우&lt;/li&gt;
          &lt;li&gt;아직 우리 정신이 얼마나 속기 쉬운지 모르거나 이와 관련된 경험이 없는 경우
            &lt;ul&gt;
              &lt;li&gt;우리는 사각지대롤 못보지만 뇌가 이러한 간극을 채우게 됨&lt;/li&gt;
              &lt;li&gt;실제로 존재하지 않는 패턴을 보는 경향 (임의적인 것에서 특정한 의미를 추론)
                &lt;ul&gt;
                  &lt;li&gt;9/11 테러 때 악마 형상의 연기를 보았다.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;사람이 의심의 여지없이 모든 것을 받아들일 때, 자신의 마음이 자기자신을 속이고 있는지 아닌지 알 수 없음&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;불교나 힌두교에서 하는 수행으로 생각하는 것
    &lt;ul&gt;
      &lt;li&gt;불교나 힌두교를 믿는 사람들만 어떤 목표나 생각, 감정을 가지고 있는 것이 아님&lt;/li&gt;
      &lt;li&gt;불교나 힌두교를 믿는 사람들만 사물을 객관적으로 흥미를 가지는 방향으로 볼 수 있는 것이 아님&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;마음챙김으로 인해 유해지거나 약해질 것이라는 생각
    &lt;ul&gt;
      &lt;li&gt;마음책김을 통해 더 친절하고 상냥한 사람이 될 것이라는 이론은 어느 정도 사실임&lt;/li&gt;
      &lt;li&gt;하지만 이것이 유하고 약한 사람이 된다는 것은 아님&lt;/li&gt;
      &lt;li&gt;사실은 상냥하면서 강인할 수 있음
        &lt;ul&gt;
          &lt;li&gt;마하트마 간디, 만델라, 마더 테레사, 마틴 루터 킹…&lt;/li&gt;
          &lt;li&gt;상냥한 것은 약한 것이 아님&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;살면서 스트레스를 감당할 수 없게 된 사람들이 마음챙김에 의지하게 됨
        &lt;ul&gt;
          &lt;li&gt;마음챙김은 약한 사람들이나 하는 것이라는 오해가 발생&lt;/li&gt;
          &lt;li&gt;사실은 인과관계의 방향성을 오해하여 내린 잘못된 결론&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;마음챙김의-인지에-대한-장애-요인&quot;&gt;마음챙김의 인지에 대한 장애 요인&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;생각하지 않는 것에 대한 오해 (이를 너무 어렵거나 이상하다고 생각하는 것)
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;마음챙김은 생각을 안하는 것이 아니라, 사고 관계를 바꾸는 것&lt;/strong&gt;이라 할 수 있음
        &lt;ul&gt;
          &lt;li&gt;사고와 감정의 관계를 더 잘 인식하고 바꾸는 것이 목표임&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;생각에 사로잡히지 않는 것, 특히 자신의 생각으로 무언가를 판단하거나 나누거나 견해를 밝힐 때.&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;자신의 생각을 감정이나 다른 생각과 분리하고 이를 있는 그대로 관찰하는 것 (순수한 자각)&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;순수한 자각이라는 경험을 시도해보지 않고 이를 무엇인지 알길 바라는 것
    &lt;ul&gt;
      &lt;li&gt;마음챙김을 수행하기 전에 이것 (순수한 자각) 이 무엇인지 알고 싶어함
        &lt;ul&gt;
          &lt;li&gt;하지만 이를 시도해보기 전에는 이것이 무엇인지 알기 어려움.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;순수한 자각을 느끼는 데 너무 많은 시간이 걸릴 지 모른다는 두려움&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;하루에 12분 정도만 마음 챙김 훈련을 해도 가능함. (5주간 하루 5분만 해도 충분함)&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;마음챙김의-준비와-관련된-장애-요인&quot;&gt;마음챙김의 준비와 관련된 장애 요인&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;마음챙김을 규칙적으로 실천하는 데 있어 필요한 시간, 장소, 에너지를 따로 마련하는 것
    &lt;blockquote&gt;
      &lt;p&gt;&lt;strong&gt;뜻이 있는 곳에 길이 있다.&lt;/strong&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;ul&gt;
      &lt;li&gt;스티븐 프레스필드 “최고의 나를 꺼내라”
        &lt;ul&gt;
          &lt;li&gt;머릿속에서 자기 자신에 저항하는 목소리를 자기자신의 생각이 아니라 여기고 넘기는 것&lt;/li&gt;
          &lt;li&gt;프로의 경우 다친 채로 경기를 하는 법을 안다.&lt;/li&gt;
          &lt;li&gt;프로의 경우 우리가 늘 하는 것을 꾸준히 하면서도 자신의 일과 삶을 사랑한다.&lt;/li&gt;
          &lt;li&gt;프로의 경우 자신의 일에 대해 과하게 생각하지 않는다.
            &lt;ul&gt;
              &lt;li&gt;일에 실패하더라도 실패나 성공을 개인적인 일로 받아들이지 않음.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;성공의 열쇠 : &lt;strong&gt;1분이나 2분정도, 자신이 가장 편한 방법으로 자신의 목표한 바를 현실적으로 이뤄내기&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;수행을 하는 것에 대해 좌절하지 않는다면, 이를 완전히 포기할 가능성도 줄어든다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;목표를 너무 높게 잡지 않기.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;목표와 자신의 상태를 자주 비교하지 말기.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;지금 내가 하는 마음 챙김 수행이 다른 어떤 것들과도 같지 않다는 것을 분명히 하기
        &lt;ul&gt;
          &lt;li&gt;현실이 어떻게 흘러갈지 지켜보는 것만을 목표로 삼기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;최대한 벽에 붙어있는 파리가 되고자 의도하기&lt;/li&gt;
      &lt;li&gt;벽에 붙어있는 파리가 되고자 하는 수행을 끝낸 뒤, 스스로 자기연민을 할 것이라 다짐하거나, 흔들리지 않는 열정 추구를 할 것이라고 다짐하기.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;존재-수행-presence-practice&quot;&gt;존재 수행 (Presence Practice)&lt;/h1&gt;

&lt;h2 id=&quot;마음챙김&quot;&gt;마음챙김&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;어떤 일에 대해 함부로 판단하지 않고 이를 있는 그대로 관찰하는 것&lt;/li&gt;
  &lt;li&gt;머리 속에서 자신이 벽에 붙어 있는 파리가 되는 것
    &lt;ul&gt;
      &lt;li&gt;머리 속에 일어나는 생각(생각, 감정, 목표 등)을 관찰하기만 하는 것&lt;/li&gt;
      &lt;li&gt;대부분 사람들은 신체적 감각을 관찰하는 것은 잘하지만 머리속에 일어나는 일을 관찰하는 것은 힘들어함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;마음챙김을 수행하기 위해서는 호흡을 관찰하는 것이 최고의 방법&lt;/strong&gt;이라고 함
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;호흡은 늘 상태가 변화하기 때문&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;생각은 고정시키거나 관찰하기가 힘듬&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;숨을 쉴 때 느껴지는 부가적인 감각들을 관찰하기&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;존재수행&quot;&gt;존재수행&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;편안한 몸
    &lt;ul&gt;
      &lt;li&gt;준비
        &lt;ul&gt;
          &lt;li&gt;의자에 편한 자세로 앉기&lt;/li&gt;
          &lt;li&gt;두 발은 땅에 닿은 채로 두기&lt;/li&gt;
          &lt;li&gt;등은 의자에 살짝 기대기 (등은 곶게 펴고 집중하기)&lt;/li&gt;
          &lt;li&gt;손바닥은 위로 두든 아래도 두든 편하게 두기&lt;/li&gt;
          &lt;li&gt;필요하다면 눈을 감기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;머리 꼭대기로 집중하기&lt;/li&gt;
      &lt;li&gt;차례대로, 신체 부위별로 차례대로 머리에서부터 내려가면서 머리, 두피, 얼굴, 목에 집중하기&lt;/li&gt;
      &lt;li&gt;어깨의 긴장을 풀기&lt;/li&gt;
      &lt;li&gt;몸을 훑고 내려오며 어떤 긴장감이나 뻣뻣함, 통증이 있는지 확인하고 이를 제거하기 (흘려보내기)&lt;/li&gt;
      &lt;li&gt;발끝까지 감각을 훑고 다시 머리 끝까지 올라가며 집중하기&lt;/li&gt;
      &lt;li&gt;몸이 완전히 편안한 상태가 될 때까지 이를 한번에서 두번정도 반복&lt;/li&gt;
      &lt;li&gt;몸이 편한상태가 되면 자연스럽게 호흡에 집중
        &lt;ul&gt;
          &lt;li&gt;공기가 몸을 통과하며 복부가 자연스럽게 상승, 하강함&lt;/li&gt;
          &lt;li&gt;자연스럽게 관찰 (몸에서 어떤 감각이 느껴지는지)
            &lt;ul&gt;
              &lt;li&gt;몸의 이완, 호흡이 일정해짐&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;깔끔하고, 차분하고 조용한 마음
    &lt;ul&gt;
      &lt;li&gt;마음의 창에 집중하기
        &lt;ul&gt;
          &lt;li&gt;무슨 생각을 하고있고, 무슨 프로그램을 계획하고 있는지&lt;/li&gt;
          &lt;li&gt;모든 창을 닫기 (하나씩, 천천히)&lt;/li&gt;
          &lt;li&gt;조용한 마음을 회복하기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;열린 마음
    &lt;ul&gt;
      &lt;li&gt;가슴 부분 (심장) 으로 집중하기&lt;/li&gt;
      &lt;li&gt;심장이 피를 뿜어낼 때의 온기를 느껴보기&lt;/li&gt;
      &lt;li&gt;감정의 심장을 느껴보기&lt;/li&gt;
      &lt;li&gt;감정의 심장을 아주 약간만 열어보기
        &lt;ul&gt;
          &lt;li&gt;다른 사람의 감정과 느낌을 받아들일 수 있을 정도&lt;/li&gt;
          &lt;li&gt;나의 느낌과 감정을 남에게도 열어보기&lt;/li&gt;
          &lt;li&gt;마음과 마음이 연결되는 유대감을 느껴보기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;민감한 음파 탐지
    &lt;ul&gt;
      &lt;li&gt;감각을 일깨워서 주변에 일어나고 있는 모든 일이 보내는 신호를 감지하기
        &lt;ul&gt;
          &lt;li&gt;에어컨이 작동되는 소리&lt;/li&gt;
          &lt;li&gt;발에 닿는 땅&lt;/li&gt;
          &lt;li&gt;아로마향이나 커피향&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;눈을 뜨고도 할 수 있고, 눈을 감고도 할 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;에너지 유도
    &lt;ul&gt;
      &lt;li&gt;모든 존재가 각자의 에너지를 가지고 있음 (아우라) - 몸보다 15~20cm 정도 더 김&lt;/li&gt;
      &lt;li&gt;자신만의 독특한 에너지 장을 발견&lt;/li&gt;
      &lt;li&gt;타인과 함께라면
        &lt;ul&gt;
          &lt;li&gt;에너지 장을 조금 늘려 옆에 있는 사람에게 까지 이를 넓혀보기&lt;/li&gt;
          &lt;li&gt;타인의 에너지 장에 들어가보기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;혼자라면
        &lt;ul&gt;
          &lt;li&gt;하나의 따듯하고 넓은 에너지 장을 만들어보기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;자신의 내면이 어떻게 변화하는지 느껴보기&lt;/li&gt;
  &lt;li&gt;확언하기
    &lt;ul&gt;
      &lt;li&gt;지금 이 순간은, 내가 지켜야 할 것이 없다.&lt;/li&gt;
      &lt;li&gt;지금 이 순간은, 내가 발전시킬 것이 없다.&lt;/li&gt;
      &lt;li&gt;지금 이 순간은, 내가 두려워할 것이 없다.&lt;/li&gt;
      &lt;li&gt;지금 이 순간은 오직, 내가 여기에 존재할 뿐이다.&lt;/li&gt;
      &lt;li&gt;지금 이 순간은, 내가 여기에 존재할 뿐이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;현재의 순간에 집중하기
    &lt;ul&gt;
      &lt;li&gt;지금 느끼는 감정은?&lt;/li&gt;
      &lt;li&gt;지금 자신의 존재의 느낌은?&lt;/li&gt;
      &lt;li&gt;현재의 순간을 최대한 생생하게 느끼기&lt;/li&gt;
      &lt;li&gt;현재의 순간을 필요할 때 필요한만큼 느끼기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;마음-챙김의-역설&quot;&gt;마음 챙김의 역설&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;현재 일어나고 있는 일과 밀접하게 관련이 있으면서, 현재 일어나고 있는 일과 조금 거리를 두고 (남의 일처럼) 관찰하는 것
    &lt;ul&gt;
      &lt;li&gt;관찰을 하는 것이 자신의 생각으로 진행되는 것이 아님
        &lt;ul&gt;
          &lt;li&gt;자신의 생각으로 관찰을 하게 되면 판단,분류,특정한 생각으로 인해 실체와 거리를 두게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;순수한 자각이라는 시각 (의식) 으로 진행
        &lt;ul&gt;
          &lt;li&gt;자신과 자신이 관찰하는 사물 사이에 거리가 없게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;부정적인 감정을 한번 더 생각하거나 이에 대해 다른 생각으로 전환하는 것보다, 있는 그대로 받아들이는 것이 오히려 덜 불행해지는 길이 된다.
    &lt;ul&gt;
      &lt;li&gt;불쾌한 일을 단순히 관찰해보기만 한다면, 실제보다 머리 속으로 더 부정적으로 생각하고 있다는 것을 알게 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모든 사람들이 마음챙김을 통해 모든 부정적인 상황을 쉽게 받아들일 수 있는 것은 아님
    &lt;ul&gt;
      &lt;li&gt;감정 조절 전략을 사용한 뒤, 마음챙김을 수행&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;마음챙김을 통해 &lt;strong&gt;반응유연성&lt;/strong&gt;을 기를 수 있는데, 이는 &lt;strong&gt;상황에 유연하게 반응하기보다는 어떤 반응을 보일지 선택하는 것&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;마음챙김이 자발성을 꺾는 것과 같아 보이기도 함 (심사숙고를 통해서만 결정을 내릴 수 있는 것처럼 보임)&lt;/li&gt;
      &lt;li&gt;마음챙김을 한다고 해서 생각에 과하게 의존하게 되지는 않음&lt;/li&gt;
      &lt;li&gt;빠른 판단 (생각) 을 하는 것은 자발적인 것이 아닌 반사적인 것&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;생각의 속도를 늦춰 더 선명하게 바라볼 수 있는 능력을 가지게 되면 선택권이 생기게 됨&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="A Life of Happiness and Fulfillment (행복하고 보람찬 삶)" /><category term="Coursera" /><category term="Indian School of Business" /><category term="Dr. Rajagopal Raghunathan" /><category term="A Life of Happiness and Fulfillment" /><category term="긍정심리학" /><category term="행복" /><category term="내부의 근원" /><summary type="html">내부의 근원을 무시하는 것</summary></entry><entry><title type="html">A Life of Happiness and Fulfillment - 06. 삶에 대한 불신</title><link href="https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-06_Distrusting-Life/" rel="alternate" type="text/html" title="A Life of Happiness and Fulfillment - 06. 삶에 대한 불신" /><published>2022-09-19T18:00:00+09:00</published><updated>2022-09-19T18:00:00+09:00</updated><id>https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-06_Distrusting%20Life</id><content type="html" xml:base="https://bluesplatter.com/a%20life%20of%20happiness%20and%20fulfillment%20(%ED%96%89%EB%B3%B5%ED%95%98%EA%B3%A0%20%EB%B3%B4%EB%9E%8C%EC%B0%AC%20%EC%82%B6)/Happiness-06_Distrusting-Life/">&lt;h1 id=&quot;삶에-대한-불신&quot;&gt;삶에 대한 불신&lt;/h1&gt;

&lt;h2 id=&quot;삶에-대한-불신-1&quot;&gt;삶에 대한 불신&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;삶은 한 치도 예상할 수 없음&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;좋지 않은 일이라 생각했던 것이 기회가 되고, 좋은 일이라 생각했던 것이 악재가 되기도 함&lt;/li&gt;
      &lt;li&gt;따라서 &lt;strong&gt;어떤 결과(외적인 상황)를 통해 우리가 행복할 거라고 생각하면 안 됨&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;외적인 상황은 행복에 10% 정도 밖에 영향을 주지 않음&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;행복을 결과에 연관짓지 않는 삶
    &lt;ul&gt;
      &lt;li&gt;이 일이 좋은 일일지, 나쁜 일일지 누가 아나요? (Good thing, Bad thing, Who knows?)&lt;/li&gt;
      &lt;li&gt;어떤 일이 일어났을 때 그 일이 자기에게 좋은 일일지 나쁜 일일지 반드시 알 필요가 없음
        &lt;ul&gt;
          &lt;li&gt;But 모든 일 (승진, 결혼 등)을 이런 방식으로 생각하면 다시는 행복해질 수 없는 것 아닌가?&lt;/li&gt;
          &lt;li&gt;But 목표(성취) 없는 삶 : 모든 결과가 매력적이지 않게 느껴지거나, 어떤 결과를 추구해야 할지 모르게 됨?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;행복의-요소로서의-과정과-결과&quot;&gt;행복의 요소로서의 과정과 결과&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;결과가 아니라면 어떤 목적을 우리의 행복과 연관 지어야 하는가?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;바빠지고자-하는-욕구&quot;&gt;바빠지고자 하는 욕구&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;사람들은 아무것도 안하고 있을 때보다 바쁠 때 더 행복함&lt;/li&gt;
  &lt;li&gt;아무것도 안하는 선택지를 선택한 사람들도 약간의 조건만 달라지더라도 바빠지는 선택지로 선택을 바꿈
    &lt;ul&gt;
      &lt;li&gt;바쁜 데에도 이유가 필요함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;물론 계속 바쁜 것을 선호하는 것은 아님&lt;/li&gt;
  &lt;li&gt;약간의 조건이 아닌 의미있는 일을 한다고 생각될 때 더 좋은 결과를 도출함
    &lt;ul&gt;
      &lt;li&gt;바쁠 때 (의미있는 일을 할 때), 바쁘지 않을 때보다 더 행복하다는 사실은 행복을 어떤 일의 결과에 맡기지 않아도 된다는 것을 뜻함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;목표로-향해-나아가는-과정에서-행복을-느낄-수-있음&quot;&gt;목표로 향해 나아가는 과정에서 행복을 느낄 수 있음&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;시험을 준비하는 과정에서의 행복&lt;/li&gt;
  &lt;li&gt;휴가를 떠날 계획을 하는 과정에서의 행복&lt;/li&gt;
  &lt;li&gt;행복과 결과를 연관짓지 않더라도 여전히 행복할 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;사전-선호도를-가지고-사후-판단주의를-가지지-않는-것&quot;&gt;사전 선호도를 가지고, 사후 판단주의를 가지지 않는 것&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;사전 선호도 : 결과가 발생하기 전에 특정한 결과를 선호하는 것&lt;/li&gt;
  &lt;li&gt;사후 판단주의 : 결과를 행복과 연결짓는 것&lt;/li&gt;
  &lt;li&gt;사후 판단주의를 가지지 않는 것 : 이미 일어난 결과를 판단하지 않는 것
    &lt;ul&gt;
      &lt;li&gt;삶에 대해 무관심해지는 것이 아님&lt;/li&gt;
      &lt;li&gt;추구하고자 하는 목적을 모르는 것을 의미하는 것이 아님&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;최선을 다해서 바람직하지 않은 결과를 피하는 것&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;일의 과정에서 행복을 느끼는 데에 초점을 맞추는 것&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;목표 달성을 위한 3가지 광범위한 접근법
    &lt;ul&gt;
      &lt;li&gt;열정에 대한 집착적 추구 : 특정한 결과에 대한 강한 선호도를 가지는 것 (X)
        &lt;ul&gt;
          &lt;li&gt;결과에 영향을 받게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;열정에 대한 무관심 추구 : 결과 전, 후 모두 무관심한 것을 추구하는 것 (X)
        &lt;ul&gt;
          &lt;li&gt;이러한 방식은 가능한 방법이 아님 (인간은 욕구를 가지고 있음)&lt;/li&gt;
          &lt;li&gt;생명력 없는 삶&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;흔들리지 않는 열정 추구&lt;/strong&gt; (O)
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;결과가 발생하기 전에 선호도를 가짐&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;결과가 발생하고 나서 그 결과를 판단하지 않음&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;쉽지 않은 일 (일관성에 위배) 이지만 불가능한 일은 아님&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;냉정한-흔들리지-않는-열정-추구를-위한-3가지-전략&quot;&gt;냉정한 (흔들리지 않는) 열정 추구를 위한 3가지 전략&lt;/h1&gt;

&lt;h2 id=&quot;과거의-부정적인-결과를-되돌아-보기&quot;&gt;과거의 부정적인 결과를 되돌아 보기&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;과거 가고싶었던 학교에 진학하지 못한 일이나, 뼈가 부러진 일 등&lt;/li&gt;
  &lt;li&gt;이 과거의 일이 얼마나 부정적이었는지 생각해보기 &amp;gt; &lt;strong&gt;시간이 지나면서 부정적인 일은 힘을 잃는다.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;과거의 부정적인 일에 대한 생각을 바꿀 수 있다.&lt;/strong&gt; &amp;gt; &lt;strong&gt;과거의 것을 바꿀 수 있다면 현재의 것(부정적)도 바꿀 수 있다.&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;당장의 행복 수치가 올라감&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;부정적으로 보였던 일에서 더 많은 기회를 발견할 수 있음&lt;/strong&gt; &amp;gt; 이러한 시점은 성공의 중요한 요인&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;부정적인-일이-일어나도-부정적인-일을-통해-발생하는-기회에-대해-감사하기&quot;&gt;부정적인 일이 일어나도 (부정적인 일을 통해 발생하는 기회에 대해) 감사하기&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;부정적인 일에 대해 감사할 수는 없어도 모든 순간에 대해서는 감사할 수 있을 것
    &lt;ul&gt;
      &lt;li&gt;폭력, 전쟁, 억압, 착취에 감사할 수는 없음&lt;/li&gt;
      &lt;li&gt;개인적으로 친구를 잃거나 사별한 것에 대해 감사할 수는 없음&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;이러한 일을 벗어나 (어렵지만) 주어진 순간, 주어진 기회에 대해 감사할 수 있음&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;고통을 통해 교훈을 얻을 수 있음 (예: 인내 등)&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;매일-세가지-나쁜-일을-적는-것&quot;&gt;매일 세가지 나쁜 일을 적는 것&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;그날 있었던 안 좋은 일을 적어보고 나중에 이것이 좋은 것임을 아는 활동&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;영적인-태도의-수용&quot;&gt;영적인 태도의 수용&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;무슨 일이 일어나도 이것이 최선일 것이라 믿는 태도 &amp;gt; 암묵적인 신뢰&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;현재 겉으로 보기에는 부정적으로 보이는 결과를 얻어도 결국 이를 통해 성장, 더 행복해지고 의미있는 삶을 살게 될 것&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;냉정한 (흔들리지 않는) 열정 추구를 위한 3가지 전략 &amp;gt; 결국 영적인 태도의 수용을 하는 활동
    &lt;ul&gt;
      &lt;li&gt;삶은 신뢰할 수 있다는 가설&lt;/li&gt;
      &lt;li&gt;모든 일은 최선이라는 가설&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;플라시보 효과 &amp;gt; 진실이라고 믿는 개인의 주관적인 믿음이 객관적인 진실을 형성&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;삶이 선하고 믿을 수 있는 것이라 믿는게 행복의 측면에서 더 낫다.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;영성 : 사물을 바라보는 방식. 세상을 받아들이는 방식. 표면보다 더 깊은 것을 보는 것
    &lt;ul&gt;
      &lt;li&gt;예 : 고통, 삶, 죽음은 표면적 의미보다 더 깊은 의미를 가지고 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;전환을-통한-세-가지-좋은-일-활동-7일간&quot;&gt;전환을 통한 세 가지 좋은 일 (활동-7일간)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;하루 동안 있었던 좋았던 일 세가지를 적기&lt;/li&gt;
  &lt;li&gt;나쁜 일 세가지가 결과적으로 좋은 효과를 가져온 경우를 적기 (극도로 안 좋은 일은 적지 않기)&lt;/li&gt;
&lt;/ul&gt;</content><author><name>HY03</name><email>hyunik03@gmail.com</email></author><category term="A Life of Happiness and Fulfillment (행복하고 보람찬 삶)" /><category term="Coursera" /><category term="Indian School of Business" /><category term="Dr. Rajagopal Raghunathan" /><category term="A Life of Happiness and Fulfillment" /><category term="긍정심리학" /><category term="행복" /><category term="삶에 대한 불신" /><summary type="html">삶에 대한 불신</summary></entry></feed>